#!/usr/bin/perl
#
# get_iplayer
#
# Lists and downloads BBC iPlayer audio and video streams
#
# Author: Phil Lewis
# Email: iplayer (at sign) linuxcentre.net
# Web: http://linuxcentre.net
# License: GPLv3 (see LICENSE.txt)
# Date: September 26th 2008
#
my $version = 0.77;
#
# Supports: 
# * Downloading h.264/Mov/Quicktime Video and mp3/realaudio Radio streams and podcasts from BBC iPlayer site
# * Downloads streams from BBC iPlayer site (--get)
# * Re-jigs the mov file so that video can be streamed and start faster on some players
# * Resume downloads of partially downloaded files
# * Indexing of all available Podcast, Radio and TV (i.e. listed) iPlayer programs using Atom and RSS feeds
# * Info option (--info) to get full programme metadata
# * Caching of Programme Index (default 4hrs)
# * Lists programmes added since last cache refresh (--since)
# * Creation of a basic html index file (--html <file>)
# * Execution of a custom user command after every successful download (--command)
# * HTTP Proxy support (maybe broken for now on some proxies) (--proxy)
# * Regex search on programme name capability (makes it useful to run this from crontab)
# * Regex search on long programme description/episode capability (--long)
# * Regex search on channel and category (--channel, --category, --exclude-channel, --exclude-category)
# * Search by type 'tv', 'radio', 'podcast', or 'all' (default: --type=tv)
# * Save default options in ~/.get_iplayer/config (--save)
# * Tested on Linux (Fedora 6/7/8/9, Centos/RHEL 5, *Ubuntu, Xebian, Unslung/NSLU2)
# * Tested on MacOSX, and Windows ActivePerl (no realaudio radio to stdout), cygwin
#
# Requires:
# * perl 5.8
# * LWP (libwww-perl)
# * mplayer, lame and tee (for realaudio radio transcoded mp3 stdout support only)
#
# Todo:
# ** Use non-shell tee?
# ** Fix non-uk detection - iphone auth?
# ** Index/Download live radio streams w/schedule feeds to assist timing
# ** Podcasts for 'local' stations are missing (only a handful). They use a number of different station ids which will involve reading html to determine rss feed. 
# ** Remove all rtsp/mplayer/lame/tee dross when realaudio streams become obselete (not quite yet)
#
# Known Issues:
# * In ActivePerl/windows downloaded iPhone video files do not get renamed (remain with .partial.mov)
# * vlc does not quit after downloading an rtsp N96 video stream (ctrl-c is required) - need a --play-and-quit option if such a thing exists
#
#
# Changes 0.77 - 20080926
# * Added non-mandatory idv3 tagging support for MP3 files downloaded by new iPhone method using external id3 tools if available
# * Added --id3v2 option to specify non-default location of id3v2 binary
# * Added <fileprefix>, <ext> and <dir> to %prog so that it can be used in --command option
# * Tidied up definition of cache files
# * Cache files no longer get deleted upon get_iplayer upgrade
#
# Changes 0.76 - 20080924
# * A few cosmetic tweaks like the 'number of matches' appearing at the end on the programme listing
# * Set the 'type' option according to the index number specified (i.e. 1xxxx => radio, < 10000 => tv and > 19999 => podcast)
# * The programme cache is additionally read if an index is specified in its number range
#
# Changes 0.75 - 20080924
# * If an MP3 version of a radio programme is not available the default is to try to use the realaudio stream
# * --realaudio option prevents the downloading of radio MP3 streams
# * --mp3audio option ensures that realaudio stream is not used as a fallback for radio
# * A few cosmetic bug fixes
# * Check for existence of a PID when an index number is specified
# * Don't add empty pids to download_history file
# * Added --force-download option to override download history
# * Report final average download speed / bitrate / duration after successful downloads (not for rtsp streams)
# * Remove stdout logs - messes with stdout streaming in too many strange ways
# * Does not check download history if nowrite & stdout options are specified
#
# Changes 0.74 - 20080924
# * Changed --list-categories and --list-channels to use --list <element_name> where element name can be any element name in the %prog hash
# * Bugfix --streaminfo doesn't add to download history
# * Allow h.264 download subroutines to now also download mp3 audio for iphone radio
# * Added --realaudio option for radio downloads where mp3 download is not available
#
# Changes 0.73 - 20080922
# * Now remembers which PIDs/programmes have already been downloaded and will prevent downloading them after you delete the programme
# * The PID download history file is in ~/.get_iplayer/download_history
# * Added --outputradio --outputtv --outputpodcast to override --output so that different directories can be used for different programme types respectively
# * Added --list-categories and --list-channels support
# * Fixed a bug introduced in version 0.72 which --type=all would only result in --type=podcast
#
# Changes 0.72 - 20080919
# * time stamping of cache entries
# * Added --since option to see what was added since a number of hours ago (using above time stamps)
# * --flush now refreshes the cache rather than simply deleting it (retains timestamps)
#
# Changes 0.71 - 20080916
# * Workaround BBC World Service using non-standard PID format (not starting with b0)
# * Workaround BBC World Service HTTP redirects which contain extra whitespace and newlines around RTSP urls which mplayer does not like
# * Workaround BBC World Service where mediaselector metadata sets XML element kind="" instead of kind="audio"
#
# Changes 0.70 - 20080916
# * Added BBC World Service to iPlayer radio channels list
#

use Env qw[@PATH];
use Fcntl;
use File::Copy;
use File::Path;
use File::stat;
use Getopt::Long;
use HTML::Entities;
use HTTP::Cookies;
use HTTP::Headers;
use IO::Seekable;
use IO::Socket;
use LWP::ConnCache;
#use LWP::Debug qw(+);
use LWP::UserAgent;
use POSIX qw(mkfifo);
use strict;
use warnings;
use Time::Local;
use URI;

$|=1;
my %opt = ();


# Print to STDERR if not quiet unless verbose or debug
sub logger(@) {
	# Make sure quiet can be overridden by verbose and debug options
	print STDERR $_[0] if (! $opt{quiet}) || $opt{verbose} || $opt{debug};
}

sub usage {
	logger <<EOF;
get_iplayer v$version, Usage:
Search Programmes:  get_iplayer [<search options>] [<regex|index|pid|pidurl> ...]
Download files:     get_iplayer --get [<search options>] <regex|index|pid|pidurl> ...
                    get_iplayer --pid <pid|pidurl> [<options>]
Stream Downloads:   get_iplayer --stdout [<options>] <regex|index|pid|pidurl> | mplayer -cache 2048 -
Update get_iplayer: get_iplayer --update

Search Options:
 <regex|index|pid|url>         Search programme names based on given pattern
 -l, --long                    Additionally search in long programme descriptions / episode names
 --channel <regex>             Narrow search to matched channel(s)
 --category <regex>            Narrow search to matched categories
 --exclude-channel <regex>     Narrow search to exclude matched channel(s)
 --exclude-category <regex>    Narrow search to exclude matched catogories
 --type <radio|tv|podcast|all> Only search in these types of programmes (tv is default)
 --since <hours>               Limit search to programmes added to the cache in the last N hours

Display Options:
 -l, --long                    Display long programme descriptions / episode names and other data
 --terse                       Only show terse programme info (does not affect searching)
 -i, --info                    Show full programme metadata (only if number of matches < 50)
 --list <categories|channel>   Show a list of available categories/channels for the selected type and exit

Download Options:
 -g, --get                     Download matching programmes
 -x, --stdout                  Additionally stream to STDOUT (so you can pipe output to a player)
 -p, --proxy <url>             Web proxy URL spec
 --pid <pid|url>               Download an arbitrary pid that does not appear in the index
 --force-download              Ignore download history
 --realaudio                   Use the RealAudio radio stream and not the MP3 stream
 --mp3audio                    Use the MP3 radio stream for radio and dont fallback to the RealAudio stream
 --wav                         In radio realaudio mode output as wav and don't transcode to mp3
 --raw                         In radio realaudio mode output as raw realaudio and don't transcode to mp3
 --n96                         In TV mode download/stream low quality Nokia N96 H.264 stream (alpha)
 --bandwidth                   In radio realaudio mode specify the link bandwidth in bps for rtsp streaming (default 512000)
 --subtitles                   In TV mode, download subtitles into srt/SubRip format if available
 --suboffset <offset>          Offset the subtitle timestamps by the specified number of milliseconds
 -t, --test                    Test only - no download (will show programme type)
 
Output Options:
 -o, --output <dir>            Default Download output directory for all downloads
 --outputradio <dir>           Download output directory for radio
 --outputtv <dir>              Download output directory for tv
 --outputpodcast <dir>         Download output directory for podcasts
 -s, --subdir                  Downloaded files into Programme name subdirectory
 -n, --nowrite                 No writing of file to disk (use with -x to prevent a copy being stored on disk)
 -w, --whitespace              Keep whitespace (and escape chars) in filenames
 -q, --quiet                   No logging output
 -c, --command <command>       Run user command after successful download using args such as <pid>, <name> etc
 
Config Options:
 -f, --flush, --refresh        Refresh cache
 -e, --expiry <secs>           Cache expiry in seconds (default 4hrs)
 --symlink <file>              Create symlink to <file> once we have the header of the download
 --fxd <file>                  Create Freevo FXD XML in specified file
 --mythtv <file>               Create Mythtv streams XML in specified file
 --xml-channels                Create freevo/Mythtv menu of channels -> programme names -> episodes
 --xml-names                   Create freevo/Mythtv menu of programme names -> episodes
 --xml-alpha                   Create freevo/Mythtv menu sorted alphabetically by programme name
 --html <file>                 Create basic HTML index of programmes in specified file
 --mplayer <path>              Location of mplayer binary
 --lame <path>                 Location of lame binary
 --id3v2 <path>                Location of id3v2 binary
 --vlc <path>                  Location of vlc binary
 --streaminfo                  Returns all of the media stream urls of the programme(s)
 -v, --verbose                 Verbose
 -u, --update                  Update get_iplayer if a newer one exists
 -h, --help                    Help
 --save                        Save specified options as default in .get_iplayer/config
EOF
	exit 1;
}

# Get cmdline params
my $save;
# This is where all profile data/caches/cookies etc goes
my $profile_dir;
# This is where system-wide default options are specified
my $optfile_system;
# Options on unix-like systems
if ( defined $ENV{HOME} ) {
	$profile_dir = $ENV{HOME}.'/.get_iplayer';
	$optfile_system = '/etc/get_iplayer/options';

# Otherwise look for windows style file locations
} elsif ( defined $ENV{USERPROFILE} ) {
	$profile_dir = $ENV{USERPROFILE}.'/.get_iplayer';
	$optfile_system = $ENV{ALLUSERSPROFILE}.'/get_iplayer/options';
}
# Make profile dir if it doesnt exist
mkdir $profile_dir if ! -d $profile_dir;
# Personal options go here
my $optfile = "${profile_dir}/options";

# Parse options if we're not saving options (system-wide options are overridden by personal options)
if ( ! grep /\-\-save/, @ARGV ) {
	$opt{debug} = 1 if grep /\-\-debug/, @ARGV;
	read_options_file($optfile_system);
	read_options_file($optfile);
}

# Allow bundling of single char options
Getopt::Long::Configure ("bundling");
# cmdline opts take precedence
GetOptions(
	"help|h"			=> \$opt{help},
	"get|g"				=> \$opt{get},
	"long|l"			=> \$opt{long},
	"verbose|v"			=> \$opt{verbose},
	"flush|refresh|f"		=> \$opt{flush},
	"output|o=s"			=> \$opt{output},
	"outputtv|o=s"			=> \$opt{outputtv},
	"outputradio|o=s"		=> \$opt{outputradio},
	"outputpodcast|o=s"		=> \$opt{outputpodcast},
	"proxy|p=s"			=> \$opt{proxy},
	"stdout|stream|x"		=> \$opt{stdout},
	"subdirs|subdir|s"		=> \$opt{subdir},
	"no-write|nowrite|n"		=> \$opt{nowrite},
	"expiry|e=n"			=> \$opt{expiry},
	"test|t"			=> \$opt{test},
	"whitespace|ws|w"		=> \$opt{whitespace},
	"update|u"			=> \$opt{update},
	"debug"				=> \$opt{debug},
	"channel=s"			=> \$opt{channel},
	"category=s"			=> \$opt{category},
	"q|quiet"			=> \$opt{quiet},
	"symlink|freevo=s"		=> \$opt{symlink},
	"fxd=s"				=> \$opt{fxd},
	"mythtv=s"			=> \$opt{mythtv},
	"xml-channels|fxd-channels"	=> \$opt{xmlchannels},
	"xml-names|fxd-names"		=> \$opt{xmlnames},
	"xml-alpha|fxd-alpha"		=> \$opt{xmlalpha},
	"html=s"			=> \$opt{html},
	"terse"				=> \$opt{terse},
	"pid=s"				=> \$opt{pid},
	"type=s"			=> \$opt{type},
	"exclude-category=s"		=> \$opt{excludecategory},
	"exclude-channel=s"		=> \$opt{excludechannel},
	"i|info"			=> \$opt{info},
	"c|command=s"			=> \$opt{command},
	"mplayer=s"			=> \$opt{mplayer},
	"lame=s"			=> \$opt{lame},
	"id3v2=s"			=> \$opt{id3v2},
	"vlc=s"				=> \$opt{vlc},
	"n96"				=> \$opt{n96},
	"realaudio"			=> \$opt{realaudio},
	"mp3audio"			=> \$opt{mp3audio},
	"force-download"		=> \$opt{forcedownload},
	"wav"				=> \$opt{wav},
	"raw"				=> \$opt{raw},
	"bandwidth=n"			=> \$opt{bandwidth},
	"subtitles"			=> \$opt{subtitles},
	"suboffset=n"			=> \$opt{suboffset},
	"streaminfo"			=> \$opt{streaminfo},
	"since=n"			=> \$opt{since},
	"list=s"			=> \$opt{list},
	"save"				=> \$save,
) || die usage();
usage() if $opt{help};

# Save opts if specified
save_options_file($optfile) if $save;

# Default to type=tv
$opt{type} = 'tv' if ! $opt{type};
# Expand 'all' to various prog types
$opt{type} = 'tv,radio,podcast' if $opt{type} =~ /(all|any)/i;
# Ensure lowercase
$opt{type} = lc( $opt{type} );

# Options
my %download_dir	= (
	'tv'		=> $opt{outputtv} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
	'radio'		=> $opt{outputradio} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
	'podcast'	=> $opt{outputpodcast} || $opt{output} || $ENV{IPLAYER_OUTDIR} || '.',
);
my %cachefile = (
	'tv'		=> "${profile_dir}/tv.cache",
	'radio'		=> "${profile_dir}/radio.cache",
	'podcast'	=> "${profile_dir}/podcast.cache",
);
my $get_iplayer_stream	= 'get_iplayer_freevo_wrapper';	# Location of wrapper script for streaming with mplayer/xine on freevo
my $historyfile		= "${profile_dir}/download_history";
my $cookiejar		= "${profile_dir}/cookies";
my $namedpipe 		= "${profile_dir}/namedpipe.$$";
my $cache_secs 		= $opt{expiry} || 14400;
my $lwp_request_timeout	= 20;
my $info_limit		= 40;
my $mplayer		= $opt{mplayer} || 'mplayer';
my $mplayer_opts	= '-nolirc';
$mplayer_opts		.= ' -really-quiet' if $opt{quiet};
my $lame		= $opt{lame} || 'lame';
my $lame_opts		= '-f ';
$lame_opts		.= '--quiet ' if $opt{quiet};
my $vlc			= $opt{vlc} || 'cvlc';
my $vlc_opts		= '-vv';
my $id3v2		= $opt{id3v2} || 'id3v2';
my $tee			= 'tee';
my $bandwidth		= $opt{bandwidth} || 512000; # Download bandwidth bps used for rtsp streams
# Set quiet, test and get options if we're asked for streaminfo
if ( $opt{streaminfo} ) {
	$opt{test} = 1;
	$opt{get} = 1;
	$opt{quiet} = 1;
}

# URLs
my $search_page_prefix		= 'http://www.bbc.co.uk/iplayer/atoz/?filter=azgroup%3A*&start=';
my $channel_feed_url		= 'http://feeds.bbc.co.uk/iplayer'; # /$channel/list/limit/200
my $pid_page_url_prefix		= 'http://www.bbc.co.uk/iplayer/episode/';
my $web_bug_2_url		= 'http://www.bbc.co.uk/iplayer/framework/img/o.gif?';
my $audio_download_prefix	= 'http://www.bbc.co.uk/mediaselector/4/mtis/stream';
my $video_download_prefix	= 'http://www.bbc.co.uk/mediaselector/3/auth/iplayer_streaming_http_mp4';
my $prog_page_prefix		= 'http://www.bbc.co.uk/programmes';
my $thumbnail_prefix		= 'http://www.bbc.co.uk/iplayer/images/episode';
my $metadata_xml_prefix		= 'http://www.bbc.co.uk/iplayer/metafiles/episode'; # /${pid}.xml
my $metadata_mobile_prefix	= 'http://www.bbc.co.uk/iplayer/widget/episodedetail/episode'; # /${pid}/template/mobile/service_type/tv/
my $podcast_index_url		= 'http://www.bbc.co.uk/radio/opml/bbc_podcast_opml.xml';
my $version_url			= 'http://linuxcentre.net/get_iplayer/VERSION-get_iplayer';
my $update_url			= 'http://linuxcentre.net/get_iplayer/get_iplayer';

my %channels;
$channels{tv} = {
	'bbc_one'				=> 'tv|BBC One',
	'bbc_two'				=> 'tv|BBC Two',
	'bbc_three'				=> 'tv|BBC Three',
	'bbc_four'				=> 'tv|BBC Four',
	'cbbc'					=> 'tv|CBBC',
	'cbeebies'				=> 'tv|CBeebies',
	'bbc_news24'				=> 'tv|BBC News 24',
	'bbc_parliament'			=> 'tv|BBC Parliament',
	'bbc_one_northern_ireland'		=> 'tv|BBC One Northern Ireland',
	'bbc_one_scotland'			=> 'tv|BBC One Scotland',
	'bbc_one_wales'				=> 'tv|BBC One Wales',
	'bbc_webonly'				=> 'tv|BBC Web Only',
	'bbc_hd'				=> 'tv|BBC HD',
	'categories/news/tv'			=> 'tv|BBC News',
	'categories/sport/tv'			=> 'tv|BBC Sport',
#	'categories/tv'				=> 'tv|All',
#	'categories/signed/tv'			=> 'tv|Signed',
};

$channels{radio} = {
	'bbc_1xtra'				=> 'radio|BBC 1Xtra',
	'bbc_radio_one'				=> 'radio|BBC Radio 1',
	'bbc_radio_two'				=> 'radio|BBC Radio 2',
	'bbc_radio_three'			=> 'radio|BBC Radio 3',
	'bbc_radio_four'			=> 'radio|BBC Radio 4',
	'bbc_radio_five_live'			=> 'radio|BBC Radio 5 live',
	'bbc_radio_five_live_sports_extra'	=> 'radio|BBC 5 live Sports Extra',
	'bbc_6music'				=> 'radio|BBC 6 Music',
	'bbc_7'					=> 'radio|BBC 7',
	'bbc_asian_network'			=> 'radio|BBC Asian Network',
	'bbc_radio_foyle'			=> 'radio|BBC Radio Foyle',
	'bbc_radio_scotland'			=> 'radio|BBC Radio Scotland',
	'bbc_radio_ulster'			=> 'radio|BBC Radio Ulster',
	'bbc_radio_wales'			=> 'radio|BBC Radio Wales',
	'bbc_world_service'			=> 'radio|BBC World Service',
#	'categories/radio'			=> 'radio|All',
};


# User Agents
my %user_agent = (
  	coremedia	=> 'Apple iPhone v1.1.1 CoreMedia v1.0.0.3A110a',
  	safari		=> 'Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A110a Safari/419.3',
  	update		=> "get_iplayer updater (v${version} - $^O)",
  	desktop		=> 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-GB; rv:1.9) Gecko/2008052906 Firefox/3.0',
);

# Setup signal handlers
$SIG{INT} = $SIG{PIPE} =\&cleanup;


# Sanity check some conflicting options
if ($opt{nowrite} && (!$opt{stdout})) {
	logger "ERROR: Cannot download to nowhere\n";
	exit 1;
}

# Programme data structure
# $prog{$pid} = {
#	'index'		=> <index number>,
#	'name'		=> <programme short name>,
#	'episode'	=> <Episode info>,
#	'desc'		=> <Long Description>,
#	'available'	=> <Date/Time made available or remaining>,
#	'duration'	=> <duration in HH:MM:SS>
#	'versions'	=> <comma separated list of versions, e.g Original, Signed>
#	'thumbnail'	=> <programme thumbnail url>
#	'channel	=> <channel>
#	'categories'	=> <Comma separtaed list of categories>
# 	'type'		=> <Type: tv, radio or podcast>
#	'timeadded'	=> <timestamp when programme was added to cache>
#	'longname'	=> <Long name (only parsed in stage 1 download)>,
#	'version'	=> <selected version e.g Original, Signed, etc - only set before d/load>
#	'filename'	=> <Path and Filename of saved file - set only while downloading>
#	'dir'		=> <Filename Directory of saved file - set only while downloading>
#	'fileprefix'	=> <Filename Prefix of saved file - set only while downloading>
#	'ext'		=> <Filename Extension of saved file - set only while downloading>
#};
my %prog;
# Hash to obtain pid given an index
my %index_pid;
my $now;
my $childpid;

# Web proxy
my $proxy_url = $opt{proxy} || $ENV{HTTP_PROXY} || $ENV{http_proxy} || '';
logger "INFO: Using Proxy $proxy_url\n" if $proxy_url;

# Update this script if required
if ($opt{update}) {
	update_script();
}

# Check for valid dload dirs or create them
for ( keys %download_dir ) {
	if ( ! -d $download_dir{$_} ) {
		logger "INFO: Created directory $download_dir{$_}\n";
		mkpath($download_dir{$_});
	}
}


# Get stream links from BBC iplayer site or from cache (also populates all hashes) specified in --type option
get_links( $_ ) for split /,/, $opt{type};


# List elements (i.e. 'channel' 'categories') if required and exit
if ( $opt{list} ) {
	list_unique_element_counts( $opt{list} );
	exit 0;
}

# Write HTML and XML files if required
create_html( sort {$a <=> $b} keys %index_pid ) if $opt{html};
create_xml( $opt{fxd}, sort {$a <=> $b} keys %index_pid ) if $opt{fxd};
create_xml( $opt{mythtv}, sort {$a <=> $b} keys %index_pid ) if $opt{mythtv};

# Get arbitrary pid
if ( $opt{pid} ) {
	# Remove any url parts from the pid
	$opt{pid} =~ s/^.*(b0[a-z,0-9]{6}).*$/$1/g;
	# Retry loop
	my $count;
	my $retries = 3;
	my $retcode;
	exit 1 if ( ! $opt{streaminfo} ) && check_download_history( $opt{pid} );
	while ( $count < $retries && ($retcode = download_programme( $opt{pid} )) eq 'retry' ) {
		logger "WARNING: Retrying download for PID $opt{pid}\n";
		$count++;
	}
	# Add to history and Run post download command if download was successful
	if ($retcode == 0) {
		add_to_download_history( $opt{pid} );
		run_user_command( $opt{pid}, $opt{command} ) if $opt{command};
	}	
	exit 0;
}

# Assume search term is '.*' if nothing is specified - i.e. lists all programmes
push @ARGV, '.*' if ! $ARGV[0];

# Parse remaining args
my @match_list;
for ( @ARGV ) {
	chomp();

	# If Numerical value < 30000
	if ( /^[\d]+$/ && $_ < 30000) {
		push @match_list, $_;

	# If PID then find matching programmes with this PID
	} elsif ( /^.*b0[a-z,0-9]{6}.*$/ ) {
		s/^.*(b0[a-z,0-9]{6}).*$/$1/g;
		push @match_list, get_regex_matches( $1 );

	# Else assume this is a programme name regex
	} else {
		push @match_list, get_regex_matches( $_ );
	}
}

# De-dup matches and retain order
my %seen = ();
my @unique = grep { ! $seen{ $_ }++ } @match_list;
@match_list = @unique;

# Go get the cached data for other programme types if the index numbers require it
my %require;
for ( @match_list ) {
	$require{tv} = 1 if $_ >= 1 && $_ < 10000 && ( ! $require{tv} ) && $opt{type} !~ /tv/;
	$require{radio} = 1 if $_ >= 10000 && $_ < 20000 && ( ! $require{radio} ) && $opt{type} !~ /radio/;
	$require{podcast} = 1 if $_ >= 20000 && $_ < 30000 && ( ! $require{podcast} ) && $opt{type} !~ /podcast/;
}
# Get extra required programme caches
logger "INFO: Additionally getting cached programme data for ".(join ', ', keys %require)."\n" if %require > 0;
# Get stream links from BBC iplayer site or from cache (also populates all hashes)
for (keys %require) {
	# Get $_ stream links
	get_links( $_ );
	# Add new prog types to the type option
	$opt{type} .= ",$_";
}

# Display list for download
logger "Matches:\n" if @match_list;
@match_list = list_progs( @match_list );

# Do the downloads based on list of index numbers if required
if ( $opt{get} || $opt{stdout} ) {
	for (@match_list) {
		# Retry loop
		my $count = 0;
		my $retries = 3;
		my $retcode;
		my $pid = $index_pid{$_};
		next if ( ! $opt{streaminfo} ) && check_download_history( $pid );
		# Skip and warn if there is no pid
		if ( ! $pid ) {
			logger "ERROR: No PID for index $_ (try using --type option ?)\n";
			next;
		}
		while ( $count < $retries && $pid && ($retcode = download_programme( $pid )) eq 'retry' ) {
			logger "WARNING: Retrying download for '$prog{$pid}{name} - $prog{$pid}{episode}'\n";
			$count++;
		}
		# Add to history, tag file, and run post download command if download was successful
		if ($retcode == 0) {
			add_to_download_history( $pid );
			tag_file( $pid );
			run_user_command( $pid, $opt{command} ) if $opt{command};
		}
	}
}

exit 0;




# Lists progs given an array of index numbers, also retuens an array with non-existent entries removed
sub list_progs {
	my $ua;
	my @checked;
	# Setup user agent for a persistent connection to get programme metadata
	if ( $opt{info} ) {
		$ua = LWP::UserAgent->new;
		$ua->timeout([$lwp_request_timeout]);
		$ua->proxy( ['http'] => $proxy_url );
		$ua->agent( $user_agent{desktop} );
		$ua->conn_cache(LWP::ConnCache->new());
		# Truncate array if were lisiting info and > $info_limit entries are requested - be nice to the beeb!
		if ( $#_ >= $info_limit ) {
			$#_ = $info_limit - 1;
			logger "WARNING: Only processing the first $info_limit matches\n";
		}
	}

	for (@_) {
		my $pid = $index_pid{$_};
		next if ! $pid;
		list_prog_entry( $pid, '' );
		push @checked, $_;
		logger get_pid_metadata( $ua, $pid )."\n" if $opt{info};
	}
	logger "\n";

	logger "INFO: ".($#checked + 1)." Matching Programmes\n";
	return @checked;
}



# Display a line containing programme info (using long, terse, and type options)
sub list_prog_entry {
	my ( $pid, $prefix ) = ( @_ );
	my $type = '';
	$type = "$prog{$pid}{type}, " if $opt{type} !~ /^(tv|radio|podcast)$/i;
	# Remove some info depending on type
	my $optional;
	$optional = ", '$prog{$pid}{channel}', $prog{$pid}{categories}, $prog{$pid}{versions}" if $prog{$pid}{type} eq 'tv';
	$optional = ", '$prog{$pid}{channel}', $prog{$pid}{categories}" if $prog{$pid}{type} eq 'radio';
	$optional = ", '$prog{$pid}{available}', '$prog{$pid}{channel}', $prog{$pid}{categories}" if $prog{$pid}{type} eq 'podcast';
	# Display based on output options
	if ( $opt{long} ) {
		my @time = gmtime( time() - $prog{$pid}{timeadded} );
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}${optional}, $time[7] days $time[2] hours ago - $prog{$pid}{desc}\n";
	} elsif ( $opt{terse} ) {
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}\n";
	} else {
		logger "${prefix}$prog{$pid}{index}:\t${type}$prog{$pid}{name} - $prog{$pid}{episode}${optional}\n";
	}
	return 0;
}



# Get matching programme index numbers using supplied regex
sub get_regex_matches {
	my $download_regex = shift;
	my %download_hash;
	my $channel_regex = $opt{channel} || '.*';
	my $category_regex = $opt{category} || '.*';
	my $channel_exclude_regex = $opt{excludechannel} || '^ROGUE$';
	my $category_exclude_regex = $opt{excludecategory} || '^ROGUE$';
	my $since = $opt{since} || 99999;
	my $now = time();
		
	for (keys %index_pid) {
		my $pid = $index_pid{$_};

		# Only include programmes matching channels and category regexes
		if ( $prog{$pid}{channel} =~ /$channel_regex/i
		  && $prog{$pid}{categories} =~ /$category_regex/i
		  && $prog{$pid}{channel} !~ /$channel_exclude_regex/i
		  && $prog{$pid}{categories} !~ /$category_exclude_regex/i
		  && $prog{$pid}{timeadded} >= $now - ($since * 3600)
		) {

			# Search prognames/pids while excluding channel_regex and category_regex
			$download_hash{$_} = 1 if (
				$prog{$pid}{name} =~ /$download_regex/i
				|| ( $pid =~ /$download_regex/i && $download_regex =~ /b00/ )
				|| ( $pid =~ /$download_regex/i && $download_regex =~ /b00/ )
			);
			# Also search long descriptions and episode data if -l is specified
			$download_hash{$_} = 1 if (
				$opt{long} 
				&& 
				( $prog{$pid}{desc} =~ /$download_regex/i
				  || $prog{$pid}{episode} =~ /$download_regex/i
				)
			);
		}
	}
	return sort {$a <=> $b} keys %download_hash;
}


# get_links_atom (%channels)
sub get_links_atom {
	my $type = shift;
	my %channels = %{$_[0]};

	my $xml;
	my $feed_data;
	my $res;
	logger "INFO: Getting $type Index Feeds\n";
	# Setup User agent
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{desktop} );
	$ua->conn_cache(LWP::ConnCache->new());

	# Download index feed
	# Sort feeds so that category based feeds are done last - this makes sure that the channels get defined correctly if there are dups
	my @channel_list;
	push @channel_list, grep !/categor/, keys %channels;
	push @channel_list, grep  /categor/, keys %channels;
	for ( @channel_list ) {

		my $url = "${channel_feed_url}/$_/list/limit/400";
		logger "DEBUG: Getting feed $url\n" if $opt{verbose};
		$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get programme index feed for $_ from iplayer site\n");
		logger "INFO: Got ".(grep /<entry/, split /\n/, $xml)." programmes\n" if $opt{verbose};
		decode_entities($xml);	
		
		# Feed as of August 2008
		#	 <entry>
		#	   <title type="text">Bargain Hunt: Series 18: Oswestry</title>
		#	   <id>tag:feeds.bbc.co.uk,2008:PIPS:b0088jgs</id>
		#	   <updated>2008-07-22T00:23:50Z</updated>
		#	   <content type="html">
		#	     &lt;p&gt;
		#	       &lt;a href=&quot;http://www.bbc.co.uk/iplayer/episode/b0088jgs?src=a_syn30&quot;&gt;
		#		 &lt;img src=&quot;http://www.bbc.co.uk/iplayer/images/episode/b0088jgs_150_84.jpg&quot; alt=&quot;Bargain Hunt: Series 18: Oswestry&quot; /&gt;
		#	       &lt;/a&gt;
		#	     &lt;/p&gt;
		#	     &lt;p&gt;
		#	       The teams are at an antiques fair in Oswestry showground. Hosted by Tim Wonnacott.
		#	     &lt;/p&gt;
		#	   </content>
		#	   <category term="Factual" />
		#	   <category term="TV" />
		#	   <link rel="via" href="http://www.bbc.co.uk/iplayer/episode/b0088jgs?src=a_syn30" type="text/html" title="Bargain Hunt: Series 18: Oswestry" />
		#       </entry>
		#

		### New Feed
		#  <entry>
		#    <title type="text">House of Lords: 02/07/2008</title>
		#    <id>tag:bbc.co.uk,2008:PIPS:b00cd5p7</id>
		#    <updated>2008-06-24T00:15:11Z</updated>
		#    <content type="html">
		#      <p>
		#	<a href="http://www.bbc.co.uk/iplayer/episode/b00cd5p7?src=a_syn30">
		#	  <img src="http://www.bbc.co.uk/iplayer/images/episode/b00cd5p7_150_84.jpg" alt="House of Lords: 02/07/2008" />
		#	</a>
		#      </p>
		#      <p>
		#	House of Lords, including the third reading of the Health and Social Care Bill. 1 July.
		#      </p>
		#    </content>
		#    <category term="Factual" scheme="urn:bbciplayer:category" />
		#    <link rel="via" href="http://www.bbc.co.uk/iplayer/episode/b00cd5p7?src=a_syn30" type="application/atom+xml" title="House of Lords: 02/07/2008">
		#    </link>
		#  </entry>

		# Parse XML

		# get list of entries within <entry> </entry> tags
		my @entries = split /<entry>/, $xml;
		# Discard first element == header
		shift @entries;

		my ( $name, $episode, $desc, $pid, $available, $channel, $duration, $thumbnail, $type );
		foreach my $entry (@entries) {

			my $entry_flat = $entry;
			$entry_flat =~ s/\n/ /g;

			# <id>tag:bbc.co.uk,2008:PIPS:b008pj3w</id>
			$pid = $1 if $entry =~ m{<id>.*PIPS:(.+?)</id>};

			# Skip if this pid is a duplicate
			if ( defined $prog{$pid} ) {
				logger "WARNING: '$pid, $prog{$pid}{name} - $prog{$pid}{episode}, $prog{$pid}{channel}' already exists (this channel = $_)\n" if $opt{verbose};
				next;
			}

			# parse name: episode, e.g. Take a Bow: Street Feet on the Farm
			$name = $1 if $entry =~ m{<title\s*.*?>\s*(.*?)\s*</title>};
			$episode = $name;
			$name =~ s/^(.*): .*$/$1/g;
			$episode =~ s/^.*: (.*)$/$1/g;

			# This is not the availability!
			# <updated>2008-06-22T05:01:49Z</updated>
			#$available = get_available_time_string( $1 ) if $entry =~ m{<updated>(\d{4}\-\d\d\-\d\dT\d\d:\d\d:\d\d.).*?</updated>};

			#<p>    House of Lords, including the third reading of the Health and Social Care Bill. 1 July.   </p>    </content>
			$desc = $1 if $entry =~ m{<p>\s*(.*?)\s*</p>\s*</content>};

			# Parse the categories into hash
			# <category term="Factual" />
			my @category;
			for my $line ( grep /<category/, (split /\n/, $entry) ) {
				push @category, $1 if $line =~ m{<category\s+term="(.+?)"};
			}

			# Extract channel and type
			($type, $channel) = (split /\|/, $channels{$_})[0,1];

			logger "DEBUG: '$pid, $name - $episode, $channel'\n" if $opt{debug};

			# build data structure
			$prog{$pid} = {
				'name'		=> $name,
				'versions'	=> 'Original',
				'episode'	=> $episode,
				'desc'		=> $desc,
				'available'	=> 'Unknown',
				'duration'	=> 'Unknown',
				'thumbnail'	=> "${thumbnail_prefix}/${pid}_150_84.jpg",
				'channel'	=> $channel,
				'categories'	=> join(',', @category),
				'type'		=> $type,
			};
		}
	}
	logger "\n";
	return 0;
}



# Populates the index field of the prog hash as well as creating the %index_pid hash
# Should be run after getting any link lists
sub sort_indexes {

	# Add index field based on alphabetical sorting by prog name
	my %index;
	$index{tv} = 1;
	
	# Start index counter at 10001 for radio progs
	$index{radio} = 10001;

	# Start index counter at 20001 for podcast progs
	$index{podcast} = 20001;

	my @prog_pid;

	# Create unique array of '<progname|pid>'
	push @prog_pid, "$prog{$_}{name}|$_" for (keys %prog);

	# Sort by progname and index 
	for (sort @prog_pid) {
		# Extract pid
		my $pid = (split /\|/)[1];
		my $type = $prog{$pid}{type};
		$index_pid{ $index{$type} } = $pid;
		$prog{$pid}{index} = $index{$type};
		$index{$type}++;
	}
	return 0;
}



# Uses: $podcast_index_url
# get_podcast_links ()
sub get_podcast_links {

	my $xml;
	my $res;
	logger "INFO: Getting Podcast Index\n";
	# Setup User agent
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{safari} );
	$ua->conn_cache(LWP::ConnCache->new());
	
	# Method
	# (HTML: http://www.bbc.co.uk/radio/podcasts/directory/station/radio1)
	# http://www.bbc.co.uk/radio/podcasts/ip/lists/$channel.sssi => 
	# http://www.bbc.co.uk/radio/podcasts/$name/assets/iphone_keepnet.sssi => (rewrite URL)
	# ( http://downloads.bbc.co.uk/podcasts/radio/$name/rss.xml for some progs!)
	# http://downloads.bbc.co.uk/podcasts/$channel/$name/rss.xml =>

	# Method
	# $podcast_index_url (gets list of rss feeds for each podcast prog) =>
	# http://downloads.bbc.co.uk/podcasts/$channel/$name/rss.xml =>
	
	# Get top-level podcast index (OPML)
	#  <li class="li_with_image">
	#    <a href="/radio/podcasts/trintro/assets/iphone_keepnet.sssi">
	#      <div class="list-link">
	#	<span class="img">
	#	  <img class="podcast_image"
	#	  src="http://www.bbc.co.uk/radio/podcasts/trintro/assets/_70x70.jpg" />
	#	</span>
	#	<p class="podcast_title">Tom Robinson Introducing...</p>
	#      </div>
	#    </a>
	#  </li>

	# Download index feed
	my ( $name, $title );


	my $opmldata = request_url_retry($ua, $podcast_index_url, 3, '.', "WARNING: Failed to get prodcast index from site\n");
	$opmldata =~ s/\n/ /g;

	# All channels with RSS feeds have an element like: <outline text="scotland" fullname="BBC Radio Nan Gaidheal">
	my @channel_data = split /(<outline\s+text="[^"]+?"\s+fullname="[^"]+?"\s*>.*?<\/outline>)/, $opmldata;

	my $service;
	for (@channel_data) {
		# Extract channel name, service and rss feed data
		my ($channel, $data);
		$channel = $1 if m{<outline\s+text="[^"]+?"\s+fullname="([^"]+?)"\s*>};
		$data = $1 if m{<outline\s+text="[^"]+?"\s+fullname="[^"]+?"\s*>(.*?)<\/outline>};

		# Skip if there is no feed data for channel
		next if ! ($channel || $data);
			
		#print "SERVICE=$service, CHANNEL=$channel, DATA=\n$data\n";

		# Every RSS feed has an extry like below (all in a text block - not formatted like below)
		# <outline 
		#	type="rss" 
		#	imageHref="http://www.bbc.co.uk/radio/podcasts/scotlife/assets/_300x300.jpg" 
		#	xmlUrl="http://downloads.bbc.co.uk/podcasts/scotland/scotlife/rss.xml" 
		#	imageHrefTVSafe="" 
		#	text="Scottish Life" 
		#	keyname="scotlife" 
		#	active="true" 
		#	allow="all" 
		#	networkName="" 
		#	networkId="" 
		#	typicalDurationMins="0" 
		#	page="http://www.bbc.co.uk/radioscotland" 
		#	flavour="Whole Programme" 
		#	rsstype="" 
		#	rssenc="" 
		#	language="en" 
		#	description="Compelling personal stories from every possible walk of life, Scottish Life is a weekly digest of some of the most touching, engaging, funny and infuriating experiences weâ€™ve heard about on BBC Radio Scotland.  Working life, family life, love life and leisure life, Scottish Life has it all!" 
		#	bbcgenres=""
		# />

		# For each rss feed, create an entry in %podcast_channel_prog (name => feed_url)
		my %podcast_channel_prog;
		my @podcast_channel_list = split /<outline\s+type="rss"/, $data;
		for ( @podcast_channel_list ) {
			my ($name, $xmlurl);
			# Get podcast id name
			$name = $1 if m{text="(.+?)"};
			# Get nice name
			$xmlurl = $1 if m{xmlUrl="(.+?)"};
			# Skip if not valid
			next if ! ($name && $xmlurl);
			$podcast_channel_prog{ $name } = $xmlurl;
			#print "CHANNEL=$channel\tSERVICE: $service\tNAME: $name\nXMLURL=$xmlurl\n";
		}

		# Loop thru each programme name
		for ( keys %podcast_channel_prog ) {
			my ( $name, $episode, $desc, $pid, $available, $duration, $thumbnail );

			# Get RSS feeds for each podcast programme
			my $url = $podcast_channel_prog{$_};
	
			logger "DEBUG: Getting podcast feed $url\n" if $opt{verbose};
			$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get podcast feed for $service / $_ from iplayer site\n") if $opt{verbose};
			$xml = request_url_retry($ua, $url, 3, '.', '') if ! $opt{verbose};
			# Dirty hack cos some progs are under service=radio :-|
			if (! $xml) {
				my $url = "http://downloads.bbc.co.uk/podcasts/radio/$_/rss.xml";
				$xml = request_url_retry($ua, $url, 3, '.', "WARNING: Failed to get podcast feed for radio / $_ from iplayer site\n") if $opt{verbose};
				$xml = request_url_retry($ua, $url, 3, '.', '') if ! $opt{verbose};
			}
			# skip if no data
			next if ! $xml;

			logger "INFO: Got ".(grep /<media:content/, split /<item>/, $xml)." programmes\n" if $opt{verbose};
			decode_entities($xml);
	
			# First entry is channel data
			# <?xml version="1.0" encoding="utf-8"?>
			#<rss xmlns:media="http://search.yahoo.com/mrss/"
			#xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd"
			#version="2.0">
			#  <channel>
			#    <title>Stuart Maconie's Freak Zone</title>
			#    <link>http://www.bbc.co.uk/6music/shows/freakzone/</link>
			#    <description>Weekly highlights from Stuart Maconie's
			#    ...podcast is only available in the UK.</description>
			#    <itunes:summary>Weekly highlights from Stuart Maconie's
			#    ...podcast is only available in the UK.</itunes:summary>
			#    <itunes:author>BBC 6 Music</itunes:author>
			#    <itunes:owner>
			#      <itunes:name>BBC</itunes:name>
			#      <itunes:email>podcast.support@bbc.co.uk</itunes:email>
			#    </itunes:owner>
			#    <language>en</language>
			#    <ttl>720</ttl>
			#    <image>
			#      <url>
			#      http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg</url>
			#      <title>Stuart Maconie's Freak Zone</title>
			#      <link>http://www.bbc.co.uk/6music/shows/freakzone/</link>
			#    </image>
			#    <itunes:image href="http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg" />
			#    <copyright>(C) BBC 2008</copyright>
			#    <pubDate>Sun, 06 Jul 2008 20:00:05 +0100</pubDate>
			#    <itunes:category text="Music" />
			#    <itunes:keywords>Stewart Maconie, Macconie, freekzone,
			#    freakzone, macoonie</itunes:keywords>
			#    <media:keywords>Stewart Maconie, Macconie, freekzone,
			#    freakzone, macoonie</media:keywords>
			#   <itunes:explicit>no</itunes:explicit>
			#    <media:rating scheme="urn:simple">nonadult</media:rating>
	
			# Parse XML
	
			# get list of entries within <entry> </entry> tags
			my @entries = split /<item>/, $xml;
			# first element == <channel> header
			my $header = shift @entries;

			# Get podcast name
			$name = $1 if $header =~ m{<title>\s*(.+?)\s*</title>};
	
			# Parse the categories into hash
			# <itunes:category text="Music" />
			my @category;
			for my $line ( grep /<itunes:category/, (split /\n/, $header) ) {
				push @category, $1 if $line =~ m{<itunes:category\s+text="\s*(.+?)\s*"};
			}
	
			# Get thumbnail from header
			# <itunes:image href="http://www.bbc.co.uk/radio/podcasts/freakzone/assets/_300x300.jpg" />
			$thumbnail = $1 if $header =~ m{<itunes:image href="\s*(.+?)\s*"};

			# Followed by items:
			#    <item>
			#      <title>FreakZone: C'est Stuart avec le Professeur Spear et le
			#      pop francais?</title>
			#      <description>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's module.</description>
			#      <itunes:subtitle>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's
			#      module....</itunes:subtitle>
			#      <itunes:summary>Stuart and Justin discuss the sub-genre of
			#      French 'cold wave' in this week's module.</itunes:summary>
			#      <pubDate>Sun, 06 Jul 2008 20:00:00 +0100</pubDate>
			#      <itunes:duration>14:23</itunes:duration>
			#      <enclosure url="http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3"
			#      length="13891916" type="audio/mpeg" />
			#      <guid isPermaLink="false">
			#      http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</guid>
			#      <link>
			#      http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</link>
			#      <media:content url="http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3"
			#      fileSize="13891916" type="audio/mpeg" medium="audio"
			#      expression="full" duration="863" />
			#      <itunes:author>BBC 6 Music</itunes:author>
			#    </item>
	
			foreach my $entry (@entries) {
	
				my $entry_flat = $entry;
				$entry_flat =~ s/\n/ /g;
	
				# Use the link as a guid
				# <link>   http://downloads.bbc.co.uk/podcasts/6music/freakzone/freakzone_20080706-2000.mp3</link>
				$pid = $1 if $entry =~ m{<link>\s*(.+?)</link>};
	
				# Skip if this pid is a duplicate
				if ( defined $prog{$pid} ) {
					logger "WARNING: '$pid, $prog{$pid}{name} - $prog{$pid}{episode}, $prog{$pid}{channel}' already exists (this channel = $_)\n" if $opt{verbose};
					next;
				}
	
				# parse episode
				# <title>FreakZone: C'est Stuart avec le Professeur Spear et le pop francais?</title>
				$episode = $1 if $entry =~ m{<title>\s*(.*?)\s*</title>};
	
				# <pubDate>Sun, 06 Jul 2008 20:00:00 +0100</pubDate>
				$available = $1 if $entry =~ m{<pubDate>\s*(.*?)\s*</pubDate>};
	
				# <description>Stuart and Justin discuss the sub-genre of French 'cold wave' in this week's module.</description>
				$desc = $1 if $entry =~ m{<description>\s*(.*?)\s*</description>};
	
				# Duration
				$duration = $1 if $entry =~ m{<itunes:duration>\s*(.*?)\s*</itunes:duration>};
	
				# build data structure
				$prog{$pid} = {
					'name'		=> $name,
					'versions'	=> 'Original',
					'episode'	=> $episode,
					'desc'		=> $desc,
					'available'	=> $available,
					'duration'	=> $duration,
					'thumbnail'	=> $thumbnail,
					'channel'	=> $channel,
					'categories'	=> join(',', @category),
					'type'		=> 'podcast',
				};
			}
		}
	}
	logger "\n";
	return 0;
}



# Feed info:
#	# Also see http://derivadow.com/2008/07/18/interesting-bbc-data-to-hack-with/
#	# All podcasts menu (iphone)
#	http://www.bbc.co.uk/radio/podcasts/ip/
#	# All radio1 podcasts
#	http://www.bbc.co.uk/radio/podcasts/ip/lists/radio1.sssi
#	# All radio1 -> moyles podcasts
#	http://www.bbc.co.uk/radio/podcasts/moyles/assets/iphone_keepnet.sssi
#	# RSS Feed (indexed from?)
#	http://downloads.bbc.co.uk/podcasts/radio1/moyles/rss.xml
#	# aod by channel see http://docs.google.com/View?docid=d9sxx7p_38cfsmxfcq
#	# http://www.bbc.co.uk/radio/aod/availability/<channel>.xml
#	# aod index
#	http://www.bbc.co.uk/radio/aod/index_noframes.shtml
# 	# schedule feeds
#	http://www.bbc.co.uk/bbcthree/programmes/schedules.xml
#	# These need drill-down to get episodes:
#	# TV schedules by date
#	http://www.bbc.co.uk/iplayer/widget/schedule/service/cbeebies/date/20080704
#	# TV schedules in JSON, Yaml or XML
#	http://www.bbc.co.uk/cbbc/programmes/schedules.(json|yaml|xml)
#	# TV index on programmes tv
#	http://www.bbc.co.uk/tv/programmes/a-z/by/*/player
#	# TV + Radio
#	http://www.bbc.co.uk/programmes/a-z/by/*/player
#	# All TV (limit has effect of limiting to 2.? times number entries kB??)
#	# seems that only around 50% of progs are available here compared to programmes site:
#	http://feeds.bbc.co.uk/iplayer/categories/tv/list/limit/200
#	# All Radio
#	http://feeds.bbc.co.uk/iplayer/categories/radio/list/limit/999
#	# New:
#	# iCal feeds see: http://www.bbc.co.uk/blogs/radiolabs/2008/07/some_ical_views_onto_programme.shtml
#	http://bbc.co.uk/programmes/b0079cmw/episodes/player.ics
#	# Other data
#	http://www.bbc.co.uk/cbbc/programmes/genres/childrens/player
#	http://www.bbc.co.uk/programmes/genres/childrens/schedules/upcoming.ics
#
# get_links( <radio|tv|podcast> )
sub get_links {
	my @cache;
	my $now = time();
	my $type = shift;

	# Open cache file (need to verify we can even read this)
	if ( open(CACHE, "< $cachefile{$type}") ) {
		@cache = <CACHE>;
		close (CACHE);
	}

	# Read cache into %pid_old and %index_pid_old if cache exists
	my %prog_old;
	my %index_pid_old;
	if (@cache) {
		for (@cache) {
			# Populate %prog from cache
			chomp();
			my ($index, $type, $name, $pid, $available, $episode, $versions, $duration, $desc, $channel, $categories, $thumbnail, $timeadded) = split /\|/;
			# Create data structure with prog data
			$prog_old{$pid} = {
				'index'		=> $index,
				'name'		=> $name,
				'episode'	=> $episode,
				'desc'		=> $desc,
				'available'	=> $available,
				'duration'	=> $duration,
				'versions'	=> $versions,
				'channel'	=> $channel,
				'categories'	=> $categories,
				'thumbnail'	=> $thumbnail,
				'type'		=> $type,
				'timeadded'	=> $timeadded,
			};
			$index_pid_old{$index}	= $pid;
		}
	}

	# if a cache file doesn't exist/corrupted, flush option is specified or original file is older than $cache_sec then download new data
	if ( (! @cache) || (! -f $cachefile{$type}) || $opt{flush} || ($now >= ( stat($cachefile{$type})->mtime + $cache_secs )) ) {

		# Podcast only
		get_podcast_links() if $type eq 'podcast';

		# Radio and TV
		get_links_atom( $type, \%{$channels{$type}} ) if $type =~ /(tv|radio)/;

		# Sort indexes
		sort_indexes();
		
		# Open cache file for writing
		unlink $cachefile{$type};
		my $now = time();
		if ( open(CACHE, "> $cachefile{$type}") ) {
			for (sort {$a <=> $b} keys %index_pid) {
				my $pid = $index_pid{$_};
				# Only write entries for correct prog type
				if ($prog{$pid}{type} eq $type) {
					# Merge old and new data to retain timestamps
					# if the entry was in old cache then retain timestamp from old entry
					if ( $prog_old{$pid}{timeadded} ) {
						$prog{$pid}{timeadded} = $prog_old{$pid}{timeadded};
					# Else this is a new entry
					} else {
						$prog{$pid}{timeadded} = $now;
						list_prog_entry( $pid, 'Added: ' );
					}
					# write to cache file
					print CACHE "$_|$prog{$pid}{type}|$prog{$pid}{name}|$pid|$prog{$pid}{available}|$prog{$pid}{episode}|$prog{$pid}{versions}|$prog{$pid}{duration}|$prog{$pid}{desc}|$prog{$pid}{channel}|$prog{$pid}{categories}|$prog{$pid}{thumbnail}|$prog{$pid}{timeadded}\n";
				}
			}
			close (CACHE);
		} else {
			logger "WARNING: Couldn't open cache file '$cachefile{$type}' for writing\n";
		}


	# Else copy data from existing cache file into existing %prog hash
	} else {
		$prog{$_} = $prog_old{$_} for keys %prog_old;
		$index_pid{$_} = $index_pid_old{$_} for keys %index_pid_old;
	}
	return 0;
}



# Usage: download_programme (<pid>)
sub download_programme {
	my $pid = shift;

	# Setup user-agent
	# Switch off automatic redirects
	my $ua = LWP::UserAgent->new( requests_redirectable => [] );
	# Setup user agent
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 1, ignore_discard => 1 ) );

	my $dir = $download_dir{ $prog{$pid}{type} };
	$prog{$pid}{ext} = 'mov';

	# If were a podcast...
	if ( $prog{$pid}{type} eq 'podcast' ) {
		# Determine the correct filename and extension for this download
		my $filename_orig = $pid;
		$prog{$pid}{ext} = $pid;
		$filename_orig =~ s|^.+/(.+?)\.\w+$|$1|g;
		$prog{$pid}{ext} =~ s|^.*\.(\w+)$|$1|g;
		my $file_prefix = generate_download_filename_prefix($pid, $dir, "<longname> - <episode> $filename_orig");
		$prog{$pid}{fileprefix} = $file_prefix;
		$prog{$pid}{dir} = $dir;
		logger "\rINFO: File name prefix = $file_prefix                  \n";
		my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
		my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
		$prog{$pid}{filename} = $file_done;
		if ( -f $file_done ) {
			logger "WARNING: File $file_done already exists\n\n";
			return 1;
		}

		# Skip from here if we are only testing downloads
		return 0 if $opt{test};

		return download_podcast_stream( $ua, $pid, $file, $file_done );
	}

	# Create a full URL from the PID specified
	my $page = $pid_page_url_prefix.$pid;
	logger "INFO: Attempting to Download: $prog{$pid}{name} - $prog{$pid}{episode}\n";

	# Get stage_1 content
	my @content = download_stage_1($ua, $page);
	return 7 if ! @content;

	# Non-UK detection
	# Need to check this again after iplayer2 release
	#print @content;
	#if ( grep /only available to play in the UK/i, @content ) {
	#	logger "\nERROR: This service will only work from the UK or via a UK based web proxy.\n";
	#	exit 3;
	#}

	#embeddedMedia.semp.data = {
	#        pid: "b00dcqnk",
	#        availability: 0,
	#        mode: 1,
	#
	#        title: "The Chris Moyles Show: 17/09/2008",
	#        width: 640,
	#        height: 395,
	#        visualisation : {
	#                metaFile: "http://www.bbc.co.uk/iplayer/playlist/b00dcqnk"
	#        },
	#        flash: {
	#                configFile: "http://www.bbc.co.uk/emp/iplayer/config.xml",
	#                metaFile: "http://www.bbc.co.uk/iplayer/playlist/b00dcqnk"
	#        },
	#        real: {
	#                metaFile: "http://www.bbc.co.uk/iplayer/aod/playlists/pn/nc/d0/0b/RadioBridge_0530_bbc_radio_one.ram"
	#        },
	#        wmp: {
	#                metaFile: ""
	#        }
	#};

	# If we have the following then this is audio
	#real: {
	#	metaFile: "http://www.bbc.co.uk/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two.ram"	

	# Detect if this content is for radio
	my $usemp3 = 0;
	if ( grep /real:\s*.\s*metaFile:\s*".+?"/, (join ' ', @content) ) {

		# Type is definitely radio
		$prog{$pid}{type} = 'radio';
		$dir = $download_dir{ $prog{$pid}{type} };

		# Do we have an mp3 stream? (check for flash: metafile: "") - unless realaudio option is specified
		if ( $opt{realaudio} ) {
			logger "INFO: RealAudio stream media is available\n" if $opt{verbose};

		# Else check if mp3 stream available
		} else {
			if (  grep /flash:\s+.\s+configFile:\s+".+?",\s+metaFile:\s*"http.+?"/, (join ' ', @content) ) {
				$usemp3 = 1;
				$prog{$pid}{ext} = 'mp3';
				logger "INFO: MP3 stream media is available\n" if $opt{verbose};

			# if mp3audio option is specified do not fallback to realaudio
			} elsif ( $opt{mp3audio} ) {
				logger "ERROR: No MP3 stream media is available - not falling back to RealAudio\n";
				return 1;

			# if not then force realaudio option as fallback
			} else {
				$opt{realaudio} = 1;
				logger "INFO: No MP3 stream media is available - falling back to RealAudio\n" if $opt{verbose};
			}
		}

		# Use realplayer stream
		if ( $opt{realaudio} ) {

			# Check dependancies for radio programme transcoding / streaming
			# Check if we need 'tee'
			if ( (! exists_in_path($tee)) && $opt{stdout} && (! $opt{nowrite}) ) {
				logger "\nERROR: $tee does not exist in path, skipping\n";
				return 20;
			}
			# Check if we have mplayer and lame
			if ( (! $opt{wav}) && (! $opt{raw}) && (! exists_in_path($lame)) ) {
				logger "\nWARNING: Required $lame does not exist, falling back to wav mode\n";
				$opt{wav} = 1;
			}		
			if (! exists_in_path($mplayer)) {
				logger "\nERROR: Required $mplayer does not exist, skipping\n";
				return 20;
			}

			# Extract Long Name, e.g.: title: "Jonathan Ross: 05/07/2008",
			chomp( my $title = ( grep /title:\s+/, @content)[0] );
			$title =~ s/^\s*title:\s\"\s*(.+)\s*\".*$/$1/g;
			# Strip off the episode name
			$title =~ m{^(.+):\s*(.*?)$};
			$prog{$pid}{longname} = $1;
			$prog{$pid}{episode} = $2;

			# Get version => pid
			my %version_pids = get_version_pids( @content );
			my $url_2;
	
			logger "\nINFO: Checking existence of programme\n";
			$prog{$pid}{version} = 'Original';
			# Create url with appended 6 digit random number
			my $url_1 = ${audio_download_prefix}.'/'.$version_pids{Original};
		
			logger "INFO: Version = $prog{$pid}{version}\n" if $opt{verbose};
			logger "INFO: Stage 2 URL = $url_1\n" if $opt{verbose};

			# Get these web bugs to whitelist our cookie if we don't have one already
			if ( get_web_bugs($ua, @content) ) {
				logger "ERROR: Could not whitelist cookie\n";
				return 'retry';
			} 

			$url_2 = get_audio_stream_download_url( $ua, $url_1 );

			# Report error if no versions are available
			if ( ! $url_2 ) {
				logger "ERROR: No Stage 2 URL\n" if $opt{verbose};
				return 15;
			}

			# Determine the correct filenames for this download
			$prog{$pid}{ext} = 'mp3';
			$prog{$pid}{ext} = 'ra'  if $opt{raw};
			$prog{$pid}{ext} = 'wav' if $opt{wav};
			my $file_prefix = generate_download_filename_prefix( $pid, ${dir}, "<longname> - <episode> <pid>" );
			logger "\rINFO: File name prefix = $file_prefix                 \n";
			$prog{$pid}{fileprefix} = $file_prefix;
			$prog{$pid}{dir} = $dir;
			my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
			my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
			$prog{$pid}{filename} = $file_done;
			if ( -f $file_done ) {
				logger "WARNING: File $file_done already exists\n\n";
				return 1;
			}

			# Display RTMP stream data if required
			get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'all' ) if $opt{streaminfo};

			# Skip from here if we are only testing downloads
			return 0 if $opt{test};

			# Do the audio download
			return download_rtsp_stream( $ua, $url_2, $file, $file_done, $pid );
		}

	} else {
		# Type is definitely tv
		$prog{$pid}{type} = 'tv';
		$dir = $download_dir{ $prog{$pid}{type} };
	}


	# iPhone mp3/h.264 stream downloading...

	# Check if we have vlc - if not use iPhone mode
	if ( $opt{n96} && (! exists_in_path($vlc)) ) {
		logger "\nWARNING: Required $vlc does not exist, falling back to iPhone mode\n";
		$opt{n96} = 0;
	}		

	# Parse if programme available
	#    iplayer_streaming_http_mp4 : [
	#    ],  ### This part is empty == no mov version yet
	if ( grep /iplayer_streaming_http_mp4 : \[\s+\],/i, @content ) {
		logger "\rWARNING: Programme is reported as not yet ready for download\n";
		# Will return from here once satisfied that this test is reliable
		#return 11;
	} else {
		logger "\rINFO: Programme is reported as ready for download\n";
	}

	# Extract Long Name, e.g.: iplayer.episode.setTitle("DIY SOS: Series 16: Swansea");
	chomp( $prog{$pid}{longname} = ( grep /iplayer\.episode\.setTitle/, @content)[0] );
	$prog{$pid}{longname} =~ s/^\s*iplayer\.episode\.setTitle\(\"\s*(.+)\s*\".*$/$1/g;
	# Strip off the episode name
	$prog{$pid}{longname} =~ s/^(.+):.*?$/$1/g;

	# Get type => verpid
	my %version_pids = get_version_pids( @content );
	my $url_2;
	my $got_url;
	
	# Do this for each version tried in this order (if they appaered in the content)
	for my $version ( qw/ Original Signed AudioDescribed OpenSubtitled Shortened Lengthened Other / ) {

		# Change $verpid to 'Original' type if it exists, then Used 'Signed' otherwise
		if ( grep /^$version$/, keys %version_pids ) {
			logger "INFO: Checking existence of $version version\n";
			$prog{$pid}{version} = $version;
			logger "INFO: Version = $prog{$pid}{version}\n" if $opt{verbose};

			# Get these web bugs to whitelist our cookie if we don't have one already
			if ( get_web_bugs($ua, @content) ) {
				logger "ERROR: Could not whitelist cookie\n";
				return 16;
			} 
			$url_2 = get_iphone_stream_download_url( $ua, $version_pids{$version} );
			$got_url = 1;
		}
		# Break out of loop if we have an actual URL
		last if $got_url && $url_2;
	}

	# Report error if no versions are available
	if ( ! $got_url ) {
		logger "ERROR: No versions exist for download\n";
		return 14;
	}
	# Report error if failed to get URL for version
	if ( $got_url && ! $url_2 ) {
		logger "ERROR: No Stage 2 URL\n" if $opt{verbose};
		# If mp3 audio stream does not exist force realaudio mode and retry
		if ( $usemp3 && ! $opt{mp3audio}) {
			$opt{realaudio} = 1;
			return 'retry';
		}
		return 15;
	}
	
	# Display media stream data if required
	get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'all' ) if $opt{streaminfo};

	# Determine the correct filenames for this download
	my $file_prefix = generate_download_filename_prefix( $pid, $dir );
	logger "\rINFO: File name prefix = $file_prefix                 \n";
	$prog{$pid}{fileprefix} = $file_prefix;
	$prog{$pid}{dir} = $dir;
	my $file_done = "${dir}/${file_prefix}.$prog{$pid}{ext}";
	my $file = "${dir}/${file_prefix}.partial.$prog{$pid}{ext}";
	$prog{$pid}{filename} = $file_done;
	if ( -f $file_done ) {
		logger "WARNING: File $file_done already exists\n\n";
		return 1;
	}

	# Skip from here if we are only testing downloads
	return 0 if $opt{test};

	# Get subtitles if they exist and are required
	my $subfile_done;
	my $subfile;
	if ( $opt{subtitles} ) {
		$subfile_done = "${dir}/${file_prefix}.srt";
		$subfile = "${dir}/${file_prefix}.partial.srt";
		download_subtitles( $ua, $subfile, $version_pids{ $prog{$pid}{version} } );
	}

	# Do the N96 h.264 download
	my $return;
	if ( $opt{n96} ) {
		my $url = get_media_stream_data( $pid, $version_pids{ $prog{$pid}{version} }, 'n96' );
		$return = download_h264_low_stream( $ua, $url, $file, $file_done );

	# Do the iPhone h.264 download
	} elsif ( $prog{$pid}{type} eq 'tv' ) {
		$return = download_iphone_stream( $ua, $url_2, $file, $file_done, 1 );

	# Do the iPhone mp3 download
	} elsif ( $prog{$pid}{type} eq 'radio' ) {
		$return = download_iphone_stream( $ua, $url_2, $file, $file_done, 0 );
		# If the iphone mp3 download fails then it's probably not ready yet so retry using realaudio
		$opt{realaudio} = 1 if $return eq 'retry';
	}
	
	# Rename the subtitle file accordingly
	move($subfile, $subfile_done) if $opt{subtitles} && -f $subfile;

	return $return;
}



# Download Subtitles
#GET http://www.bbc.co.uk/mediaselector/4/mtis/stream/b008dc8r
#<?xml version="1.0" encoding="UTF-8"?>                                     
#<mediaSelection xmlns="http://bbc.co.uk/2008/mp/mediaselection">           
#<media kind="captions"                                                     
#        type="application/ttaf+xml"   >                                    
#        <connection                                                        
#                priority="10"                                              
#                kind="http"                                                
#                server="http://www.bbc.co.uk/iplayer/subtitles/"           
#                identifier="b0008dc8rstreaming89808204.xml"                
#                href="http://www.bbc.co.uk/iplayer/subtitles/b0008dc8rstreaming89808204.xml" 
#        />                                                                                   
#</media>                                                                                     
#....
sub download_subtitles {
	my ( $ua, $file, $verpid ) = @_;
	my $suburl;
	my $subs;
	logger "INFO: Getting Subtitle metadata for $verpid\n" if $opt{verbose};
	my $xml = request_url_retry($ua, 'http://www.bbc.co.uk/mediaselector/4/mtis/stream/'.$verpid, 3, '', '');

	# flatten
	$xml =~ s/\n/ /g;

	# Extract url
	$suburl = $1 if $xml =~ m{<media\s+kind="captions".+?href="(.+?)".+?</media>};

	# Return if we have no url
	if (! $suburl) {
		logger "INFO: Subtitles not available\n";
		return 2;
	}

	logger "INFO: Getting Subtitles from $suburl\n" if $opt{verbose};

	# Open subs file
	unlink($file);
	my $fh = open_file_append($file);

	# Download subs
	$subs = request_url_retry($ua, $suburl, 2);
	if (! $subs ) {
		logger "ERROR: Subtitle Download failed\n";
		return 1;
	} else {
		logger "INFO: Downloaded Subtitles\n";
	}

	# Convert the format to srt
	# SRT:
	#1
	#00:01:22,490 --> 00:01:26,494
	#Next round!
	#
	#2
	#00:01:33,710 --> 00:01:37,714
	#Now that we've moved to paradise, there's nothing to eat.
	#
	
	# TT:
	#<p begin="0:01:12.400" end="0:01:13.880">Thinking.</p>

	my $count = 1;
	my @lines = grep /<p\s+begin/, split /\n/, $subs;
	for ( @lines ) {
		my ( $begin, $end, $sub );
		$begin = $1 if m{begin="(.+?)"};
		$end =   $1 if m{end="(.+?)"};
		$sub =	 $1 if m{>(.+?)</p>};
		if ($begin && $end && $sub ) {
			$begin =~ s/\./,/g;
			$end =~ s/\./,/g;
			if ($opt{suboffset}) {
				$begin = subtitle_offset( $begin, $opt{suboffset} );
				$end = subtitle_offset( $end, $opt{suboffset} );
			}
			decode_entities($sub);
			# Write to file
			print $fh "$count\n";
			print $fh "$begin --> $end\n";
			print $fh "$sub\n\n";
			$count++;
		}
	}	
	close $fh;

	return 0;
}



# Returns an offset timestamp given an srt begin or end timestamp and offset in ms
sub subtitle_offset {
	my ( $timestamp, $offset ) = @_;
	my ( $hr, $min, $sec, $ms ) = split /[:,\.]/, $timestamp;
	# split into hrs, mins, secs, ms
	my $ts = $ms + $sec*1000 + $min*60*1000 + $hr*60*60*1000 + $offset;
	$hr = int( $ts/(60*60*1000) );
	$ts -= $hr*60*60*1000;
	$min = int( $ts/(60*1000) );
	$ts -= $min*60*1000;
	$sec = int( $ts/1000 );
	$ts -= $sec*1000;
	$ms = $ts;
	return "$hr:$min:$sec,$ms";
}



# Gets media streams data for this version pid
# $media = all|flashhigh|flashnormal|iphone|flashwii|flashaudio|realaudio|subtitles
sub get_media_stream_data {
	my ( $pid, $verpid, $media ) = @_;
	my $url;
	my $ua = LWP::UserAgent->new();
	# Setup user agent with redirection enabled
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 1, ignore_discard => 1 ) );
	$opt{quiet} = 0 if $opt{streaminfo};
	logger "INFO: Getting media stream metadata for $prog{$pid}{name} - $prog{$pid}{episode}, $verpid\n";
	my $xml = request_url_retry($ua, 'http://www.bbc.co.uk/mediaselector/4/mtis/stream/'.$verpid, 3, '', '');
	logger "\n$xml\n" if $opt{debug};
	# flatten
	$xml =~ s/\n/ /g;

	my ($server, $authstring, $identifier, $href);

	# h.264 high quality stream
	#	<media kind="video"
	#        width="640"
	#        height="360"
	#        type="video/mp4"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                application="bbciplayertok"
	#                kind="level3"
	#                server="bbciplayertokfs.fplive.net"
	#                identifier="mp4:b000zxf4-H26490898078"
	#                authString="d52f77fede048f1ffd6587fd47446dee"
	#        />
	if ( $media =~ /^(flashhigh|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mp4".+?encoding="h264".+?kind="level3"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP h.264 high quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP high quality stream URL: $url\n";
	}

	# h.264 normal quality stream
	#	<media kind="video"
	#        width="512"
	#        height="288"
	#        type="video/x-flv"
	#        encoding="vp6"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp41752.edgefcs.net"
	#                identifier="secure/b000zxf4-streaming90898078"
	#                authString="daEdSdgbcaibFa7biaobCaYdadyaTamazbq-biXsum-cCp-FqrECnEoGBwFvwG"
	#        />
	#	</media>
	#
	if ( $media =~ /^(flashnormal|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/x-flv".+?encoding="vp6".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP h.264 normal quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP normal quality stream URL: $url\n";
	}

	# Wii h.264 standard quality stream
	#<media kind="video"
	#        width="512"
	#        height="288"
	#        type="video/x-flv"
	#        encoding="spark"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp41752.edgefcs.net"
	#                identifier="secure/5242138581547639062"
	#                authString="daEd8dLbGaPaZdzdNcwd.auaydJcxcHandp-biX5YL-cCp-BqsECnxnGEsHwyE"
	#        />
	#</media>
	if ( $media =~ /^(flashwii|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/x-flv".+?encoding="spark".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		logger "INFO: RTMP Wii normal quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP Wii normal quality stream URL: $url\n";
	}

	# iPhone h.264/mp3 stream
	#<media kind="video"
	#        width="480"
	#        height="272"
	#        type="video/mp4"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk/mediaselector/3/auth/stream/"
	#                identifier="5242138581547639062"
	#                href="http://www.bbc.co.uk/mediaselector/3/auth/stream/5242138581547639062.mp4"
	#        />
	#</media>
	if ( $media =~ /^(iphone|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mp4".+?encoding="h264".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		logger "INFO: iPhone stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$href";
		logger "INFO: iPhone stream URL: $url\n";
	}

	# Nokia N96 h.264 low quality stream
	#<media kind="video"
	#        type="video/mpeg"
	#        encoding="h264"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk/mediaselector/4/sdp/"
	#                identifier="b00108ld/iplayer_streaming_n95_wifi"
	#                href="http://www.bbc.co.uk/mediaselector/4/sdp/b00108ld/iplayer_streaming_n95_wifi"
	#        />
	#</media>
	if ( $media =~ /^(n96|all)$/ && $xml =~ m{<media\s+kind="video".+?type="video/mpeg".+?encoding="h264".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		$opt{quiet} = 1 if $opt{streaminfo};
		chomp( my $rtsp = download_block(undef, $href, $ua, 0, undef) );
		$opt{quiet} = 0 if $opt{streaminfo};
		logger "INFO: Nokia N96 h.264 low quality stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$rtsp";
		logger "INFO: Nokia N96 h.264 low quality stream URL: $url\n";
	}

	# Audio rtmp mp3
	#<media kind="audio"
	#        type="audio/mpeg"
	#        encoding="mp3"  >
	#        <connection
	#                priority="10"
	#                kind="akamai"
	#                server="cp48181.edgefcs.net"
	#                identifier="mp3:secure/radio1/RBN2_mashup_b00d67h9_2008_09_05_22_14_25"
	#                authString="daEbQa1c6cda6aHdudxagcCcUcVbvbncmdK-biXtzq-cCp-DnoFIpznNBqHnzF"
	#        />
	#</media>
	if ( $media =~ /^(flashaudio|all)$/ && $xml =~ m{<media\s+kind="audio".+?type="audio/mpeg".+?encoding="mp3".+?kind="akamai"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?authString="(.+?)"} ) {
		( $server, $identifier, $authstring ) = ( $1, $2, $3 );
		# Remove offending mp3: at the start of the identifier
		$identifier =~ s/^mp3://;
		logger "INFO: RTMP MP3 stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  authstring=$authstring\n" if $opt{verbose};
		$url = "rtmp://${server}:1935/ondemand?_fcs_vhost=${server}&auth=${authstring}&aifp=v001&slist=${identifier}";
		logger "INFO: RTMP stream URL: $url\n";
	}

	# ReadAudio stream
	#<media kind="audio"
	#       type="audio/real"
	#        encoding="real"  >
	#        <connection
	#                priority="10"
	#                kind="sis"
	#                server="http://www.bbc.co.uk"
	#                identifier="/radio/aod/playlists/9h/76/d0/0b/2000_bbc_radio_one"
	#                href="http://www.bbc.co.uk/radio/aod/playlists/9h/76/d0/0b/2000_bbc_radio_one.ram"
	#        />
	#</media>
	if ( $media =~ /^(realaudio|all)$/ && $xml =~ m{<media\s+kind="audio".+?type="audio/real".+?encoding="real".+?kind="sis"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		$opt{quiet} = 1 if $opt{streaminfo};
		chomp( my $rtsp = download_block(undef, $href, $ua, 0, undef) );
		$opt{quiet} = 0 if $opt{streaminfo};
		logger "INFO: RealAudio RTSP stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$rtsp";
		logger "INFO: RealAudio RTSP stream URL: $url\n";
	}

	# Subtitles stream
	#<media kind="captions"
	#        type="application/ttaf+xml"   >
	#        <connection
	#                priority="10"
	#                kind="http"
	#                server="http://www.bbc.co.uk/iplayer/subtitles/"
	#                identifier="b0008dc8rstreaming89808204.xml"
	#                href="http://www.bbc.co.uk/iplayer/subtitles/b0008dc8rstreaming89808204.xml"
	#        />
	#</media>
	if ( $media =~ /^(subtitles|all)$/ && $xml =~ m{<media\s+kind="captions".+?type="application/ttaf\+xml".+?kind="http"\s+server="(.+?)"\s+?identifier="(.+?)"\s+?href="(.+?)"} ) {
		( $server, $identifier, $href ) = ( $1, $2, $3 );
		logger "INFO: Subtitles stream:\nINFO:  server=$server\nINFO:  identifier=$identifier\nINFO:  href=$href\n" if $opt{verbose};
		$url = "$href";
		logger "INFO: Subtitles stream URL: $url\n";
	}

	logger "\n" if $opt{streaminfo};
	$opt{quiet} = 1 if $opt{streaminfo};
	return $url if ! $opt{streaminfo};
}



# Get stage 1 content
sub download_stage_1 {
	my ( $ua, $page ) = @_;

	logger "INFO: Stage 1 URL = $page\n" if $opt{verbose};
	logger "\rGetting iplayer programme page        " if ! $opt{verbose};

	# Stage 1: get PID and set cookie
	# This page Doesn't work with safari ua anymore....
	# If this break in future, use http://www.bbc.co.uk/mediaselector/4/json/stream/<pid> However this
	#   method does not provide anything except the next URL, cannot get other prog info from it
	$ua->agent( );
	# send request
	my $res = $ua->request( HTTP::Request->new( GET => $page ) );
	if ( ! $res->is_success ) {
		logger "\rERROR: Failed to get programme ID from iplayer site\n\n";
		return '';
	}
	return split /\n/, $res->content;
}



# Actually do the h.264/mp3 downloading
# ( $ua, $url_2, $file, $file_done, '0|1 == rearrange moov' )
sub download_iphone_stream {
	my ( $ua, $url_2, $file, $file_done, $rearrange ) = @_;

	# Stage 3a: Download 1st byte to get exact file length
	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Setup request header
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'		=> 'bytes=0-1',
	);
	my $req = HTTP::Request->new ('GET', $url_2, $h);
	my $res = $ua->request($req);
	# e.g. Content-Range: bytes 0-1/181338136
	my $file_len = $res->header("Content-Range");
	$file_len =~ s|^bytes 0-1/(\d+).*$|$1|;
	logger "INFO: Download File Length $file_len\n" if $opt{verbose};

	# Only do this if we're rearranging QT streams
	my $mdat_start = 0;
	my $moov_start = $file_len + 1;
	my $header;
	if ($rearrange) {
		# Get ftyp+wide header etc
		$mdat_start = 0x1c;
		my $buffer = download_block(undef, $url_2, $ua, 0, $mdat_start + 4);
		# Get bytes upto (but not including) mdat atom start -> $header
		$header = download_block(undef, $url_2, $ua, 0, $mdat_start - 1, $file_len);

		# Detemine moov start
		# Get mdat_end_offset_chars from downloaded block
		my $mdat_end_offset_chars = substr($buffer, $mdat_start, 4);
		my $mdat_end_offset = bytestring_to_int($mdat_end_offset_chars);
		logger "mdat_end_offset = ".get_hex($mdat_end_offset_chars)." = $mdat_end_offset\n" if $opt{verbose};
		logger "mdat_end_offset (decimal) = $mdat_end_offset\n" if $opt{verbose};
		# The MOOV box starts one byte after MDAT box ends
		$moov_start = $mdat_start + $mdat_end_offset;


		## scan 2nd level atoms in moov atom until we get stco atom(s)
		# We can skip first 8 bytes (moov atom header)
		#my $i = 8;
		#while( $i < $moov_length - 4 ) {
		#  my $atom_len = bytestring_to_int( substr($moovdata, $i, 4) );
		#  my $atom_name = substr($moovdata, $i+4, 4);
		#  logger "Parsing atom: $atom_name, length: $atom_len\n";
		#  # Increment $i by atom_len to get next atom
		#  $i += $atom_len;
		#}
	}

	# If we have partial content and wish to stream, resume the download & spawn off STDOUT from existing file start 
	# Sanity check - we cannot support downloading of partial content if we're streaming also. 
	if ( $opt{stdout} && (! $opt{nowrite}) && -f $file ) {
		logger "WARNING: Partially downloaded file exists, streaming will start from the beginning of the programme\n";
		# Don't do usual streaming code
		$opt{stdout} = 0;
		$childpid = fork();
		if (! $childpid) {
			# Child starts here
			logger "INFO: Streaming directly for partially downloaded file $file\n";
			if ( ! open( STREAMIN, "< $file" ) ) {
				logger "INFO: Cannot Read partially downloaded file to stream\n";
				exit 4;
			}
			my $outbuf;
			# Write out until we run out of bytes
			my $bytes_read = 65536;
			while ( $bytes_read == 65536 ) {
				$bytes_read = read(STREAMIN, $outbuf, 65536 );
				#logger "INFO: Read $bytes_read bytes\n";
				print STDOUT $outbuf;
			}
			close STREAMIN;
			logger "INFO: Stream thread has completed\n";
			exit 0;
		}
	}

	# Open file if required
	my $fh = open_file_append($file);

	# If the partial file already exists, then resume from the correct mdat/download offset
	my $restart_offset = $mdat_start;
	my $moovdata;
	my $moov_length = 0;

	if ($rearrange) {
		# if cookie fails then trigger a retry after deleting cookiejar
		# Determine moov atom length so we can work out if the partially downloaded file has the moov atom in it already
		$moov_length = bytestring_to_int( download_block( undef, $url_2, $ua, $moov_start, $moov_start+3 ) );
		logger "INFO: moov atom length = $moov_length                          \n" if $opt{verbose};
		# Sanity check this moov length - chances are that were being served up a duff file if this is > 10% of the file size or < 64k
		if ( $moov_length > (${moov_start}/9.0) || $moov_length < 65536 ) {
			logger "WARNING: Bad file download, deleting cookie                 \n";
			$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
			unlink $cookiejar;
			unlink $file;
			return 'retry';
		}
	}

	# If we have a too-small-sized file and not stdout and not no-write then this is a partial download
	if (-f $file && (! $opt{stdout}) && (! $opt{nowrite}) && stat($file)->size > ($moov_length+$mdat_start) ) {
		# Calculate new start offset (considering that we've put moov first in file)
		$restart_offset = stat($file)->size - $moov_length;
		logger "INFO: Resuming download from $restart_offset                        \n";
	}

	if ($rearrange) {
		# If we have no existing file, a file which doesn't yet even have the moov atom, or using stdout (or no-write option)
		if ( $opt{stdout} || $opt{nowrite} || stat($file)->size < ($moov_length+$mdat_start) ) {
			# get moov chunk into memory
			$moovdata = download_block( undef, $url_2, $ua, $moov_start, (${file_len}-1) );
			# Process the moov data so that we can relocate it (change the chunk offsets that are absolute)
			$moov_length = relocate_moov_chunk_offsets( $moovdata );
			# write moov atom to file next (yes - were rearranging the file - moov+header+mdat - not header+mdat+moov)
			logger "INFO: Appending moov+ftype+wide atoms to $file\n" if $opt{verbose};
			# Write moov atom
			print $fh $moovdata if ! $opt{nowrite};
			print STDOUT $moovdata if $opt{stdout};
			# Write header atoms (ftyp, wide)
			print $fh $header if ! $opt{nowrite};
			print STDOUT $header if $opt{stdout};
		}
	}

	# Create symlink for freevo if required
	if ( $opt{symlink} ) {
		# remove old symlink
		unlink $opt{symlink} if -l $opt{symlink};
		symlink $file, $opt{symlink};
	}

	# Start marker
	my $start_time = time();

	# Download mdat in 16MB blocks
	my $chunk_size = 0x1000000;
	for ( my $s = $restart_offset; $s < ${moov_start}-1; $s+= $chunk_size ) {
		# get mdat chunk into file
		my $retcode;
		my $e;
		# Get block end offset
		if ( ($s + $chunk_size - 1) > (${moov_start}-1) ) {
			$e = $moov_start - 1;
		} else {
			$e = $s + $chunk_size - 1;
		}
		# Get block from URL and append to $file
		if ( download_block($file, $url_2, $ua, $s, $e, $file_len, $fh ) ) {
			logger "ERROR: Could not download block $s - $e from $file\n\n";
			return 9;
		}
	}

	# end marker
	my $end_time = time();

	# Should now be able to concatenate header.block + mdat.block + moov.block to get movie!
	# Calculate average speed, duration and total bytes downloaded
	logger sprintf("INFO: Downloaded %.2fMB in %s at %5.0fkbps to %s\n", 
		($moov_start - 1 - $restart_offset) / (1024.0 * 1024.0),
		sprintf("%02d:%02d:%02d", ( gmtime($end_time - $start_time))[2,1,0] ), 
		( $moov_start - 1 - $restart_offset ) / ($end_time - $start_time) / 1024.0 * 8.0, 
		$file_done );

	# Moving file into place as complete (if not stdout)
	move($file, $file_done) if ! $opt{stdout};
	return 0;
}



# Actually do the N96 h.264 downloading
sub download_h264_low_stream {
	my ( $ua, $url_2, $file, $file_done ) = @_;

	# Change filename extension
	$file =~ s/mov$/mpg/gi;
	$file_done =~ s/mov$/mpg/gi;

	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};
	if ( ! $opt{stdout} ) {
		logger "INFO: Downloading Low Quality H.264 stream\n";
		my $cmd = "$vlc $vlc_opts --sout file/ts:${file} $url_2 1>&2";
		if ( system($cmd) ) {
			return 2;
		}

	# to STDOUT
	} else {
		logger "INFO: Streaming Low Quality H.264 stream to stdout\n";
		my $cmd = "$vlc $vlc_opts --sout file/ts:- $url_2 1>&2";
		if ( system($cmd) ) {
			return 2;
		}	
	}
	logger "INFO: Downloaded $file_done\n";
	# Moving file into place as complete (if not stdout)
	move($file, $file_done) if ! $opt{stdout};
	return 0;
}



# Actually do the rtsp downloading
sub download_rtsp_stream {
	my ( $ua, $url_2, $file, $file_done, $pid ) = @_;
	my $childpid;

	# Create named pipe
	if ( $^O !~ /^MSWin32$/ ) {
		mkfifo($namedpipe, 0700) if (! $opt{wav}) && (! $opt{raw});
	} else {
		logger "WARNING: fifos/named pipes are not supported\n" if $opt{verbose};
	}
	
	# Stage 3a: Download 1st byte to get exact file length
	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Determine offset for resuming download
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'		=> 'bytes=0-',
	);
	my $req = HTTP::Request->new ('GET', $url_2, $h);
	my $res = $ua->request($req);
	chomp( my $rtsp = $res->content );
	# String trailing/leading whitespace and newlines
	$rtsp =~ s/(^\s+|\s+$|\n)//g;
	logger "INFO: Stage 4 URL = $rtsp\n" if $opt{verbose};

	# Create ID3 tagging options for lame (escape " for shell)
	my ( $id3_name, $id3_episode, $id3_desc, $id3_channel ) = ( $prog{$pid}{name}, $prog{$pid}{episode}, $prog{$pid}{desc}, $prog{$pid}{channel} );
	$id3_name =~ s|"|\"|g for ($id3_name, $id3_episode, $id3_desc, $id3_channel);
	$lame_opts .= "--ignore-tag-errors --ty ".( (localtime())[5] + 1900 )." --tl \"$id3_name\" --tt \"$id3_episode\" --ta \"$id3_channel\" --tc \"$id3_desc\" ";

	# Use post-download transcoding using lame if namedpipes are not supported (i.e. ActivePerl/Windows)
	# (Fallback if no namedpipe support and raw/wav not specified)
	if ( (! -p $namedpipe) && ! ( $opt{raw} || $opt{wav} ) ) {
		my $cmd;
		# Remove filename extension
		$file =~ s/\.mp3$//gi;
		# Remove named pipe
		unlink $namedpipe;
		logger "INFO: Downloading wav format (followed by transcoding)\n";
		$cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=\"${file}.wav\" \"$rtsp\" 1>&2";
		if ( system($cmd) ) {
			return 2;
		}
		# Transcode
		logger "INFO: Transcoding ${file}.wav\n";
		$cmd = "$lame $lame_opts \"${file}.wav\" \"${file}.mp3\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		unlink "${file}.wav";
		move "${file}.mp3", $file_done;
		$prog{$pid}{ext} = 'mp3';

	# Fork a child to do transcoding on the fly using a named pipe written to by mplayer
	# else do direct mplayer write to wav file if:
	#  1) we don't have a named pipe available (e.g. in activeperl)
	#  2) --wav was specified to write file only
	} elsif ( $opt{wav} && ! $opt{stdout} ) {
		logger "INFO: Writing wav format\n";
		# Start the mplayer process and write to wav file
		my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=\"$file\" \"$rtsp\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		# Move file to done state
		move $file, $file_done if ! $opt{nowrite};

	# No transcoding if --raw was specified
	} elsif ( $opt{raw} && ! $opt{stdout} ) {
		# Write out to .ra ext instead (used on fallback if no fifo support)
		logger "INFO: Writing raw realaudio stream\n";
		# Start the mplayer process and write to raw file
		my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -dumpstream -dumpfile \"$file\" \"$rtsp\" 1>&2";
		logger "DEGUG: Running $cmd\n" if $opt{debug};
		if ( system($cmd) ) {
			return 2;
		}
		# Move file to done state
		move $file, $file_done if ! $opt{nowrite};

	# Use transcoding via named pipes
	} else {
		$childpid = fork();
		if (! $childpid) {
			# Child starts here
			$| = 1;
			logger "INFO: Transcoding $file\n";

			# Stream mp3 to file and stdout simultaneously
			if ( $opt{stdout} && ! $opt{nowrite} ) {
				if ( $opt{wav} || $opt{raw} ) {
					# Race condition - closes named pipe immediately unless we wait
					sleep 5;
					tee($namedpipe, $file);
					#system( "cat $namedpipe 2>/dev/null| $tee $file");
				} else {
					my $cmd = "$lame $lame_opts $namedpipe - 2>/dev/null| $tee \"$file\"";
					logger "DEGUG: Running $cmd\n" if $opt{debug};
					system($cmd);
				}

			# Stream mp3 stdout only
			} elsif ( $opt{stdout} && $opt{nowrite} ) {
				if ( $opt{wav} || $opt{raw} ) {
					sleep 5;
					tee($namedpipe);
					#system( "cat $namedpipe 2>/dev/null");
				} else {
					my $cmd = "$lame $lame_opts $namedpipe - 2>/dev/null";
					logger "DEGUG: Running $cmd\n" if $opt{debug};
					system( "$lame $lame_opts $namedpipe - 2>/dev/null");
				}

			# Stream mp3 to file directly
			} elsif ( ! $opt{stdout} ) {
				my $cmd = "$lame $lame_opts $namedpipe \"$file\" >/dev/null 2>/dev/null";
				logger "DEGUG: Running $cmd\n" if $opt{debug};
				system($cmd);
			}
			# Remove named pipe
			unlink $namedpipe;

			# Move file to done state
			move $file, $file_done if ! $opt{nowrite};
			logger "INFO: Transcoding thread has completed\n";
			exit 0;
		}
		# Start the mplayer process and write to named pipe
		# Raw mode
		if ( $opt{raw} ) {
			my $cmd = "$mplayer $mplayer_opts -cache 32 -bandwidth $bandwidth -dumpstream -dumpfile $namedpipe \"$rtsp\" 1>&2";
			logger "DEGUG: Running $cmd\n" if $opt{debug};
			if ( system($cmd) ) {
				# If we fail then kill off child processes
				kill 9, $childpid;
				return 2;
			}
		# WAV / mp3 mode
		} else {
			my $cmd = "$mplayer $mplayer_opts -cache 128 -bandwidth $bandwidth -vc null -vo null -ao pcm:waveheader:fast:file=$namedpipe \"$rtsp\" 1>&2";
			if ( system($cmd) ) {
				# If we fail then kill off child processes
				kill 9, $childpid;
				return 2;
			}
		}
		# Wait for child processes to prevent zombies
		wait;
	}
	logger "INFO: Downloaded $file_done\n";

	return 0;
}



# Actually do the podcast downloading
sub download_podcast_stream {
	my ( $ua, $url_2, $file, $file_done ) = @_;
	my $start_time = time();

	logger "INFO: Stage 3 URL = $url_2\n" if $opt{verbose};

	# Resume partial download?
	my $start = 0;
	if ( -f $file ) {
		$start = stat($file)->size;
		logger "INFO: Resuming download from $start\n";
	}

	my $fh = open_file_append($file);

	if ( download_block($file, $url_2, $ua, $start, undef, undef, $fh) != 0 ) {
		logger "ERROR: Download failed\n";
		return 22;
	} else {

		# end marker
		my $end_time = time();
		# Final file size
		my $size = stat($file)->size;
		# Calculate average speed, duration and total bytes downloaded
		logger sprintf("INFO: Downloaded %.2fMB in %s at %5.0fkbps to %s\n", 
			($size - $start) / (1024.0 * 1024.0),
			sprintf("%02d:%02d:%02d", ( gmtime($end_time - $start_time))[2,1,0] ), 
			( $size - $start ) / ($end_time - $start_time) / 1024.0 * 8.0, 
			$file_done );
		move $file, $file_done;
	}
	return 0;
}



# Get streaming video URL
sub get_iphone_stream_download_url {
		my $ua = shift;
		my $pid = shift;

		# Create url with appended 6 digit random number
		my $url_1 = ${video_download_prefix}.'/'.${pid}.'?'.(sprintf "%06.0f", 1000000*rand(0)).'%20';
		logger "INFO: media stream download URL = $url_1\n" if $opt{verbose};
		
		# Stage 2: e.g. "Location: http://download.iplayer.bbc.co.uk/iplayer_streaming_http_mp4/121285241910131406.mp4?token=iVXexp1yQt4jalB2Hkl%2BMqI25nz2WKiSsqD7LzRmowrwXGe%2Bq94k8KPsm7pI8kDkLslodvHySUyU%0ApM76%2BxEGtoQTF20ZdFjuqo1%2B3b7Qmb2StOGniozptrHEVQl%2FYebFKVNINg%3D%3D%0A"
		logger "\rGetting iplayer download URL         " if ! $opt{verbose};
		my $h = new HTTP::Headers(
			'User-Agent'	=> $user_agent{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes=0-1',
		);
		my $req = HTTP::Request->new ('GET', $url_1, $h);
		# send request
		my $res = $ua->request($req);
		# Get resulting Location header (i.e. redirect URL)
		my $url_2 = $res->header("location");
		if ( ! $res->is_redirect ) {
			logger "ERROR: Failed to get redirect from iplayer site\n\n";
			return '';
		}
		# Extract redirection Location URL
		$url_2 =~ s/^Location: (.*)$/$1/g;
		# If we get a Redirection containing statuscode=404 then this prog is not yet ready
		if ( $url_2 =~ /statuscode=404/ ) {
			logger "\rERROR: Programme is not yet ready for download\n";
			return '';
		}

		return $url_2;
}



# Get streaming audio URL (Real => rtsp)
#<media kind="audio"
#        type="audio/real"
#        encoding="real"  >
#        <connection
#                priority="10"
#                kind="sis"
#                server="http://www.bbc.co.uk"
#                identifier="/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two"
#                href="http://www.bbc.co.uk/radio/aod/playlists/gs/5d/c0/0b/0900_bbc_radio_two.ram"
#        />
#</media>
# OR
#<media kind=""
#        type="audio/real"
#        encoding="real"  >
#        <connection
#                priority="10"
#                kind="edgesuite"
#                server="http://http-ws.bbc.co.uk.edgesuite.net"
#                identifier="/generatecssram.esi?file=/worldservice/css/nb/410591221152760.ra"
#                href="http://http-ws.bbc.co.uk.edgesuite.net/generatecssram.esi?file=/worldservice/css/nb/410591221152760.ra"
#        />
#</media>
#
sub get_audio_stream_download_url {
		my $ua = shift;
		my $url_1 = shift;
		my $url_2;
		
		logger "\rGetting iplayer download URL         " if ! $opt{verbose};
		my $h = new HTTP::Headers(
			'User-Agent'	=> $user_agent{coremedia},
			'Accept'	=> '*/*',
			'Range'		=> 'bytes=0-',
		);
		my $req = HTTP::Request->new ('GET', $url_1, $h);
		# send request
		my $res = $ua->request($req);
		# Get resulting content 
		my $content = $res->content;
		# Flatten
		$content =~ s/\n/ /g;
		if ( ! $res->is_success ) {
			logger "ERROR: Failed to get audio url from iplayer site\n\n";
			return '';
		}
		# If we get a Redirection containing statuscode=404 then this prog is not yet ready
		if ( $content =~ /statuscode=404/ ) {
			logger "\rERROR: Programme is not yet ready for download\n";
			return '';
		}
		# extract ram URL
		$url_2 = $2 if $content =~ m{<media kind="(|audio)"\s*type="audio/real".*href="(.+?)"\s*};

		# If we cannot see 'encoding="real"...' then we don't have real audio transcoded format then skip
		if ( ! $url_2 ) {
			logger "\rERROR: Programme is not yet ready for download in RealAudio format\n";
			return '';
		}

		return $url_2;
}



# Given page content, extract the Versions and Pids and return in a hash: Versions => Pid
#<!--
#	iplayer.episode.setPidData("b0078vh4","b005rpmb");
#	iplayer.episode.setTitle("Razzledazzle: Dog");
#	iplayer.episode.setDownloadAvailability(1);
#	iplayer.episode.init();	
#		
#		iplayer.episode.buildVideoPlayer();
#		
#		
#//-->
sub get_version_pids {
	my @content = @_;
	# Extract pid versions 
	chomp( my $pid = (grep /iplayer\.episode\.setPidData/, @content)[0] );
	# Remove tags
	$pid =~ s/^.*\"([\w\d]+)\"\).*$/$1/g;
	# Get hash of pid => version
	my %version_pids;
	$version_pids{'Original'} = $pid;
	logger "INFO: Versions available: ".join(', ', %version_pids)."\n" if $opt{verbose};
	return %version_pids;
}



# Generate the download filename prefix given a pid and optional format such as '<longname> - <episode> <pid> <version>'
sub generate_download_filename_prefix {
	my $pid = shift;
	my $dir = shift;
	my $file = shift || "<longname> - <episode> <pid> <version>";
	# If we dont have longname defined just set it to name
	$prog{$pid}{longname} = $prog{$pid}{name} if ! $prog{$pid}{longname};

	# Create a filename
	# Tokenize and substitute $format
	for my $key ( keys %{ $prog{$pid} } ) {
		my $replace = $prog{$pid}{$key};
		$file =~ s|\<$key\>|$replace|gi;
	}
	$file =~ s|<pid>|$pid|gi;
	
	# Replace slashes with _ regardless
	$file =~ s/[\\\/]/_/g;
	# Sanitize by default
	$file =~ s/\s/_/g if ! $opt{whitespace};
	$file =~ s/[^\w_-]//gi if ! $opt{whitespace};

	# Don't create subdir if we are only testing downloads
	# Create a subdir for programme sorting option
	if ( $opt{subdir} && ! $opt{test} ) {
	        my $subdir = "$prog{$pid}{longname}";
                $subdir =~ s/[\\\/]/_/g;
                $subdir =~ s/\s/_/g if ! $opt{whitespace};
                $subdir =~ s/[^\w_-]//gi if ! $opt{whitespace};
                $file = "${subdir}/${file}";
                # Create dir if it does not exist
                mkdir("${dir}/${subdir}") if ! -d "${dir}/${subdir}";
        }

        return $file;
}



sub get_web_bugs {
	my $ua = shift;
	my @content = @_;
	my $h;
	my $req;
	my $res;
	
	# Load cookies and check if we have a BBC-UID cookie in there
	my $cookies = HTTP::Cookies->new;
	$cookies->load( $cookiejar );
	if ( $cookies->as_string =~ /BBC\-UID=/ ) {
		logger "INFO: Cookie already exists\n" if $opt{verbose};
		return 0;
	}
	
	# Parse this to get o.gif for stats web bug
	#var i = new Image(1,1); i.src = "http://stats.bbc.co.uk/o.gif?~RS~s~RS~iPlayer~RS~t~RS~Web_progi~RS~i~RS~b00cc05l~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/_proxy_/episode/b00cc05l~RS~r~RS~(none)~RS~q~RS~~RS~z~RS~17~RS~";
        chomp( my $url_1b = (grep /i\.src\s*=\s*\"http:\/\/stats\.bbc\.co\.uk\/o\.gif.*b0\w{5}.*\";/, @content)[0] );
        $url_1b =~ s/^.*i\.src\s*=\s*\"(http:\/\/stats\.bbc\.co\.uk\/o\.gif.*b0\w{5}.*)\";.*$/$1/g;
        logger "INFO: Web bug#1: $url_1b\n" if $opt{verbose};

        # Stage 1b - get o.gif web bug to whitelist cookie
        #my $url_1b = 'http://stats.bbc.co.uk/o.gif?~RS~s~RS~iplayer~RS~t~RS~Web_progi~RS~i~RS~b00c3rtd~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/page/item/b00c3rtd.shtml~RS~r~RS~(none)~RS~q~RS~q=graham+norton&amp;go=Find+Programmes&amp;scope=iplayersearch&amp;start=1&amp;version_pid=b00c3rrt~RS~z~RS~50~RS~ HTTP/1.1';
	logger "INFO: Getting iplayer 1st web bug              \r";
	#GET /o.gif?~RS~s~RS~iplayer~RS~t~RS~Web_progi~RS~i~RS~b00c3rtd~RS~p~RS~0~RS~a~RS~0~RS~u~RS~/iplayer/page/item/b00c3rtd.shtml~RS~r~RS~(none)~RS~q~RS~q=graham+norton&amp;go=Find+Programmes&amp;scope=iplayersearch&amp;start=1&amp;version_pid=b00c3rrt~RS~z~RS~50~RS~ HTTP/1.1
	#Accept: */*
	#Accept-Language: en
	#Accept-Encoding: gzip, deflate
	#Cookie: BBC-UID=54xxxxxxxxx71ad6e33cfdf040e01b44068765f2a0b061b4447fe92f6528b1ae0Mozilla%2f5%2e0%20%28iPod%3b%20U%3b%20CPU%20like%20Mac%20OS%20X%3b%20en%29
	#Referer: http://www.bbc.co.uk/iplayer/page/item/b00c3rtd.shtml?q=graham+norton&go=Find+Programmes&scope=iplayersearch&start=1&version_pid=b00c3rrt
	#User-Agent: Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3B48b Safari/419.3
	#Connection: keep-alive
	#Host: stats.bbc.co.uk
	$h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{safari},
		'Accept'	=> '*/*',
	);
	$req = HTTP::Request->new ('GET', $url_1b, $h);
	# send request
	$res = $ua->request($req);
	# Get resulting Location header (i.e. redirect URL)
	if ( ! $res->is_success ) {
		logger "ERROR: Failed to get o.gif web bug from iplayer site\n";
		# Better remove our cookie cos it probably isn't whitelisted
		$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
		unlink $cookiejar;
		return 2;
	}


	# Stage 1c - get o.gif framework web bug to whitelist cookie (5 digit random number appended)
	my $url_1c = $web_bug_2_url.(sprintf "%05.0f", 100000*rand(0));
	logger "INFO: Getting iplayer 2nd web bug             \r";
        #GET /iplayer/framework/img/o.gif?90927 HTTP/1.1
        #Accept: */*
        #Accept-Language: en
        #Accept-Encoding: gzip, deflate
        #Cookie: BBC-UID=e4xxxxxx731e0ec0d34a019ab030cb2de22aef9c407041d4343f4937d42343d40Mozilla%2f5%2e0%20%28iPod%3b%20U%3b%20CPU%20like%20Mac%20OS%20X%3b%20en%29%20AppleWebKit%2f420%2e1%20%28KHTML%2c%20like%20Gecko%29%20Version%2f3%2e0%20Mobile%2f3B48b%20Safari%2f419%2e3
        #Referer: http://www.bbc.co.uk/iplayer/page/item/b00c3rtd.shtml?q=graham+norton&go=Find+Programmes&scope=iplayersearch&start=1&version_pid=b00c3rrt
        #User-Agent: Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3B48b Safari/419.3
        #Connection: keep-alive
        #Host: www.bbc.co.uk
	$h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{safari},
		'Accept'	=> '*/*',
	);
	$req = HTTP::Request->new ('GET', $url_1c, $h);
	# send request
	$res = $ua->request($req);
	# Get resulting Location header (i.e. redirect URL)
	if ( ! $res->is_success ) {
		logger "ERROR: Failed to get 2nd o.gif web bug from iplayer site\n";
		# Better remove our cookie cos it probably isn't whitelisted
		$ua->cookie_jar( HTTP::Cookies->new( file => $cookiejar, autosave => 0, ignore_discard => 0 ) );
		unlink $cookiejar;
		return 2;
	}

	return 0;
}



# Usage: moov_length = relocate_moov_chunk_offsets(<binary string>)
sub relocate_moov_chunk_offsets {
	my $moovdata = $_[0];
	# Change all the chunk offsets in moov->stco atoms and add moov_length to them all
	# get moov atom length
	my $moov_length = bytestring_to_int( substr($moovdata, 0, 4) );
	# Use index() to seatch for a string within a string
	my $i = -1;
	while (($i = index($moovdata, 'stco', $i)) > -1) {

		# determine length of atom (4 bytes preceding stco)
		my $stco_len = bytestring_to_int( substr($moovdata, $i-4, 4) );
		logger "INFO: Found stco atom at moov atom offset: $i length $stco_len\n" if $opt{verbose};

		# loop through all chunk offsets in this atom and add offset (== moov atom length)
		for (my $j = $i+12; $j < $stco_len+$i-4; $j+=4) {
			my $chunk_offset = bytestring_to_int( substr($moovdata, $j, 4) );
			#logger "chunk_offset @ $i, $j = '".get_hex( substr($moovdata, $j, 4) )."',	$chunk_offset + $moov_length = ";
			$chunk_offset += $moov_length;
			# write back bytes into $moovdata
			substr($moovdata, $j+0, 1) = chr( ($chunk_offset >> 24) & 0xFF );
			substr($moovdata, $j+1, 1) = chr( ($chunk_offset >> 16) & 0xFF );
			substr($moovdata, $j+2, 1) = chr( ($chunk_offset >>  8) & 0xFF );
			substr($moovdata, $j+3, 1) = chr( ($chunk_offset >>  0) & 0xFF );
			#$chunk_offset = bytestring_to_int( substr($moovdata, $j, 4) );
			#logger "$chunk_offset\n";
		}

		# skip over this whole atom now it is processed
		$i += $stco_len;
	}
	# Write $moovdata back to calling string
	$_[0] = $moovdata;
	return $moov_length;
}



# Usage download_block($file, $url_2, $ua, $start, $end, $file_len, $fh);
#  ensure filehandle $fh is open in append mode
# or, $content = download_block(undef, $url_2, $ua, $start, $end, $file_len);
# Called in 4 ways:
# 1) write to real file			=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh);
# 2) write to real file + STDOUT	=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh); + $opt{stdout}==true
# 3) write to STDOUT only		=> download_block($file, $url_2, $ua, $start, $end, $file_len, $fh); + $opt{stdout}==true + $opt{nowrite}==false
# 4) write to memory (and return data)  => download_block(undef, $url_2, $ua, $start, $end, $file_len, undef);
# 4) write to memory (and return data)  => download_block(undef, $url_2, $ua, $start, $end);
sub download_block {

	my ($file, $url, $ua, $start, $end, $file_len, $fh) = @_;
	my $orig_length;
	my $buffer;
	my $lastpercent = 0;
	$now = time();

	# If this is an 'append to file' mode call
	if ( defined $file && $fh && (!$opt{nowrite}) ) {
		# Stage 3b: Download File
		$orig_length = tell $fh;
		logger "INFO: Appending to $file\n" if $opt{verbose};
	}

	# Setup request headers
	my $h = new HTTP::Headers(
		'User-Agent'	=> $user_agent{coremedia},
		'Accept'	=> '*/*',
		'Range'        => "bytes=${start}-${end}",
	);

	my $req = HTTP::Request->new ('GET', $url, $h);

	# Set time to use for download rate calculation
	# Define callback sub that gets called during download request
	# This sub actually writes to the open output file and reports on progress
	my $callback = sub {
		my ($data, $res, undef) = @_;
		# Don't write the output to the file if there is no content-length header
		return 0 if ( ! $res->header("Content-Length") );
		# If we don't know file length in advanced then set to size reported reported from server upon download
		$file_len = $res->header("Content-Length") + $start if ! defined $file_len;
		# Write output
		print $fh $data if ! $opt{nowrite};
		print STDOUT $data if $opt{stdout};
		# return if streaming to stdout - no need for progress
		return if $opt{stdout} && $opt{nowrite};
		return if $opt{quiet};
		# current file size
		my $size = tell $fh;
		# Download percent
		my $percent = 100.0 * $size / $file_len;
		# Don't update display if we haven't dowloaded at least another 0.1%
		return if ($percent - $lastpercent) < 0.1;
		$lastpercent = $percent;
		# download rates in bytes per second and time remaining
		my $rate_bps;
		my $rate;
		my $time;
		my $timecalled = time();
		if ($timecalled - $now < 1) {
			$rate = '-----kbps';
			$time = '--:--:--';
		} else {
			$rate_bps = ($size - $orig_length) / ($timecalled - $now);
			$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $rate_bps);
			$time = sprintf("%02d:%02d:%02d", ( gmtime( ($file_len - $size) / $rate_bps ) )[2,1,0] );
		}
		printf STDERR "%8.2fMB / %.2fMB %s %5.1f%%, %s remaining         \r", 
			$size / 1024.0 / 1024.0, 
			$file_len / 1024.0 / 1024.0,
			$rate,
			$percent,
			$time,
		;
	};

	my $callback_memory = sub {
		my ($data, $res, undef) = @_;
		# append output to buffer
		$buffer .= $data;
		return if $opt{quiet};
		# current buffer size
		my $size = length($buffer);
		# download rates in bytes per second
		my $timecalled = time();
		my $rate_bps;
		my $rate;
		my $time;
		my $percent;
		# If we can get Content_length then display full progress
		if ($res->header("Content-Length")) {
			$file_len = $res->header("Content-Length") if ! defined $file_len;
			# Download percent
			$percent = 100.0 * $size / $file_len;
			return if ($percent - $lastpercent) < 0.1;
			$lastpercent = $percent;
			# Block length
			$file_len = $res->header("Content-Length");
			if ($timecalled - $now < 0.1) {
				$rate = '-----kbps';
				$time = '--:--:--';
			} else {
				$rate_bps = $size / ($timecalled - $now);
				$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $rate_bps );
				$time = sprintf("%02d:%02d:%02d", ( gmtime( ($file_len - $size) / $rate_bps ) )[2,1,0] );
			}
			# time remaining
			printf STDERR "%8.2fMB / %.2fMB %s %5.1f%%, %s remaining         \r", 
				$size / 1024.0 / 1024.0,
				$file_len / 1024.0 / 1024.0,
				$rate,
				$percent,
				$time,
			;
		# Just used simple for if we cannot determine content length
		} else {
			if ($timecalled - $now < 0.1) {
				$rate = '-----kbps';
			} else {
				$rate = sprintf("%5.0fkbps", (8.0 / 1024.0) * $size / ($timecalled - $now) );
			}
			printf STDERR "%8.2fMB %s         \r", $size / 1024.0 / 1024.0, $rate;
		}
	};

	# send request
	logger "\nINFO: Downloading range ${start}-${end}\n" if $opt{verbose};
	logger "\r                              \r";
	my $res;

	# If $fh undefined then get block to memory (fh always defined for stdout or file d/load)
	if (defined $fh) {
		logger "DEBUG: writing stream to stdout, Range: $start - $end of $url\n" if $opt{verbose} && $opt{stdout};
		logger "DEBUG: writing stream to $file, Range: $start - $end of $url\n" if $opt{verbose} && !$opt{nowrite};
		$res = $ua->request($req, $callback);
		if (  (! $res->is_success) || (! $res->header("Content-Length")) ) {
			logger "ERROR: Failed to Download block\n\n";
			return 5;
		}
                logger "INFO: Content-Length = ".$res->header("Content-Length")."                               \n" if $opt{verbose};
		return 0;
		   
	# Memory Block
	} else {
		logger "DEBUG: writing stream to memory, Range: $start - $end of $url\n" if $opt{debug};
		$res = $ua->request($req, $callback_memory);
		if ( (! $res->is_success) ) {
			logger "ERROR: Failed to Download block\n\n";
			return '';
		} else {
			return $buffer;
		}
	}
}



# Converts a string of chars to it's HEX representation
sub get_hex {
        my $buf = shift;
        my $ret;
        for (my $i=0; $i<length($buf); $i++) {
                $ret .= " ".sprintf("%02lx", ord substr($buf, $i, 1) );
        }
	logger "DEBUG: HEX string value = $ret\n" if $opt{verbose};
        return $ret;
}



# Converts a string of chars to it's MSB decimal value
sub bytestring_to_int {
	# Reverse to LSB order
        my $buf = reverse shift;
        my $dec;
        for (my $i=0; $i<length($buf); $i++) {
		# Multiply byte value by 256^$i then accumulate
                $dec += (ord substr($buf, $i, 1)) * 256 ** $i;
        }
        #logger "DEBUG: Decimal value = $dec\n" if $opt{verbose};
        return $dec;
}



# version of unix tee
# Usage tee ($infile, $outfile)
# If $outfile is undef then just cat file to STDOUT
sub tee {
	my ( $infile, $outfile ) = @_;
	# Open $outfile for writing, $infile for reading
	if ( $outfile) {
		if ( ! open( OUT, "> $outfile" ) ) {
			logger "ERROR: Could not open $outfile for writing\n";
			return 1;
		} else {
			logger "INFO: Opened $outfile for writing\n" if $opt{verbose};
		}
	}
	if ( ! open( IN, "< $infile" ) ) {
		logger "ERROR: Could not open $infile for reading\n";
		return 2;
	} else {
		logger "INFO: Opened $infile for reading\n" if $opt{verbose};
	}
	# Read and redirect IN
	while ( <IN> ) {
		print $_;
		print OUT $_ if $outfile;
	}
	# Close output file
	close OUT if $outfile;
	close IN;
	return 0;
}



# Usage: $fh = open_file_append($filename);
sub open_file_append {
	local *FH;
	my $file = shift;
	# Just in case we actually write to the file - make this /dev/null
	$file = '/dev/null' if $opt{nowrite};
	if ($file) {
		if ( ! open(FH, ">> $file") ) {
			logger "ERROR: Cannot write or append to $file\n\n";
			exit 1;
		}
	}
	# Fix for binary - needed for Windows
	binmode FH;
	return *FH;
}



# Updates and overwrites this script - makes backup as <this file>.old
sub update_script {
	# Get version URL
	my $ua = LWP::UserAgent->new;
	$ua->timeout([$lwp_request_timeout]);
	$ua->proxy( ['http'] => $proxy_url );
	$ua->agent( $user_agent{update} );
	$ua->conn_cache(LWP::ConnCache->new());
	logger "INFO: Checking for latest version from linuxcentre.net\n";
	my $res = $ua->request( HTTP::Request->new( GET => $version_url ) );
	chomp( my $latest_ver = $res->content );
	if ( $res->is_success ) {
		# Compare version numbers
		if ( $latest_ver > $version ) {
			logger "INFO: New version $latest_ver available, downloading\n";
			my $res = $ua->request( HTTP::Request->new( GET => $update_url ) );		
			my $req = HTTP::Request->new ('GET', $update_url);
			# Save content into a $script_file
			my $script_file = $0;
			$ua->request($req, $script_file.'.tmp');
			# If the download was successful then copy over this script and make executable after making a backup of this script
			if ( $res->is_success ) {
				if ( copy($script_file, $script_file.'.old') ) {
					move($script_file.'.tmp', $script_file);
					chmod 0755, $script_file;
					logger "INFO: Copied new version $latest_ver into place (previous version is now called '${script_file}.old')\n";
				}
			}
		} else {
			logger "INFO: No update is necessary (latest version = $latest_ver)\n";
		}
	} else {
		logger "ERROR: Failed to connect to update site\n";
		exit 2;
	}
	exit 0;
}



# Creates the Freevo FXD or MythTV Streams meta data (and pre-downloads graphics - todo)
sub create_xml {
	my $xmlfile = shift;
	if ( ! open(XML, "> $xmlfile") ) {
		logger "ERROR: Couldn't open xml file $xmlfile for writing\n";
		return 1;
	}
	print XML '<?xml version="1.0" ?>';
	print XML '<freevo>' if $opt{fxd};
	print XML "\n<MediaStreams>\n" if $opt{mythtv};

	if ( $opt{xmlnames} ) {
		# containers sorted by prog names
		print XML "\t<container title=\"iplayer by Programme Name\">\n" if $opt{fxd};
		my %program_index;
		my %program_count;
		# create hash of programme_name -> index
	        for (@_) {
	        	$program_index{$prog{$index_pid{$_}}{name}} = $_;
			$program_count{$prog{$index_pid{$_}}{name}}++;
		}
		for my $name ( sort keys %program_index ) {
			my @count = grep /^$name$/, keys %program_index;
			print XML "\t<container title=\"".encode_entities( $name )." ($program_count{$name})\">\n" if $opt{fxd};
			print XML "\t<Streams>\n" if $opt{mythtv};
			for (@_) {
				my $pid = $index_pid{$_};
				# loop through and find matches for each progname
				if ( $prog{$index_pid{$_}}{name} =~ /^$name$/ ) {
					my $episode = encode_entities( $prog{$pid}{episode} );
					my $desc = encode_entities( $prog{$pid}{desc} );
					my $title = "${episode} ($prog{$pid}{available})";
					print XML "<movie title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</movie>\n" if $opt{fxd};
					print XML "<Stream>
						<Name>\"${title}\"</Name>
						<url>${pid}.mov</url>
						<Subtitle></Subtitle>
						<Synopsis>${desc}</Synopsis>
					</Stream>\n" if $opt{mythtv};
				}
			}			
			print XML "\t</container>\n" if $opt{fxd};
			print XML "\t</Streams>\n" if $opt{mythtv};
		}
		print XML "\t</container>\n" if $opt{fxd};
	}


	if ( $opt{xmlchannels} ) {
		# containers for prog names sorted by channel
		print XML "\t<container title=\"iplayer by Channel\">\n" if $opt{fxd};
		my %program_index;
		my %program_count;
		my %channels;
		# create hash of unique channel names and hash of programme_name -> index
	        for (@_) {
	        	$program_index{$prog{$index_pid{$_}}{name}} = $_;
			$program_count{$prog{$index_pid{$_}}{name}}++;
			$channels{$prog{$index_pid{$_}}{channel}} .= '|'.$prog{$index_pid{$_}}{name}.'|';
		}
		for my $channel ( sort keys %channels ) {
			print XML "\t<container title=\"".encode_entities( $channel )."\">\n" if $opt{fxd};
			print XML "\t<Feed>
				\t<Name>".encode_entities( $channel )."</Name>
				\t<Provider>BBC</Provider>\n
				\t<Streams>\n" if $opt{mythtv};
			for my $name ( sort keys %program_index ) {
				# Do we have any of this prog $name on this $channel?
				if ( $channels{$channel} =~ /\|$name\|/ ) {
					my @count = grep /^$name$/, keys %program_index;
					print XML "\t<container title=\"".encode_entities( $name )." ($program_count{$name})\">\n" if $opt{fxd};
					print XML "\t\t<Stream>\n" if $opt{mythtv};
					for (@_) {
						# loop through and find matches for each progname for this channel
						my $pid = $index_pid{$_};
						if ( $prog{$pid}{channel} =~ /^$channel$/ && $prog{$pid}{name} =~ /^$name$/ ) {
							my $episode = encode_entities( $prog{$pid}{episode} );
							my $desc = encode_entities( $prog{$pid}{desc} );
							my $title = "${episode} ($prog{$pid}{available})";
							print XML "<movie title=\"${title}\">
								<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
								<info><description>${desc}</description></info>
							</movie>\n" if $opt{fxd};
							print XML "\t\t<Name>$name</Name>\n\t\t<Url>${pid}.mov</Url>\n\t\t<Subtitle>${episode}</Subtitle>\n\t\t<Synopsis>${desc}</Synopsis>\n" if $opt{mythtv};
						}
					}
					print XML "\t</container>\n" if $opt{fxd};
					print XML "\t</Stream>\n" if $opt{mythtv};
				}
			}
			print XML "\t</container>\n" if $opt{fxd};
			print XML "\t</Streams>\n\t</Feed>\n" if $opt{mythtv};
		}
		print XML "\t</container>\n" if $opt{fxd};
	}


	if ( $opt{xmlalpha} ) {
		my %table = (
			'A-C' => '[abc]',
			'D-F' => '[def]',
			'G-I' => '[ghi]',
			'J-L' => '[jkl]',
			'M-N' => '[mn]',
			'O-P' => '[op]',
			'Q-R' => '[qt]',
			'S-T' => '[st]',
			'U-V' => '[uv]',
			'W-Z' => '[wxyz]',
			'0-9' => '[\d]',
		);
		print XML "\t<container title=\"iplayer A-Z\">\n";
		for my $folder (sort keys %table) {
			print XML "\t<container title=\"iplayer $folder\">\n";
			for (@_) {
				my $pid = $index_pid{$_};
				my $name = encode_entities( $prog{$pid}{name} );
				my $episode = encode_entities( $prog{$pid}{episode} );
				my $desc = encode_entities( $prog{$pid}{desc} );
				my $title = "${name} - ${episode} ($prog{$pid}{available})";
				my $regex = $table{$folder};
				if ( $name =~ /^$regex/i ) {
					print XML "<movie title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</movie>\n" if $opt{fxd};
					print XML "<Stream title=\"${title}\">
						<video><url id=\"p1\">${pid}.mov<playlist/></url></video>
						<info><description>${desc}</description></info>
					</Stream>\n" if $opt{mythtv};
				}
			}
			print XML "\t</container>\n";
		}
		print XML "\t</container>\n";
	}

	print XML '</freevo>' if $opt{fxd};
	print XML '</MediaStreams>' if $opt{mythtv};
	close XML;
}



sub create_html {
	# Create local web page
	if ( open(HTML, "> $opt{html}") ) {
		print HTML '<html><head></head><body><table border=1>';
		for (@_) {
			my $pid = $index_pid{$_};
			my $name = encode_entities( $prog{$pid}{name} );
			my $episode = encode_entities( $prog{$pid}{episode} );
			my $desc = encode_entities( $prog{$pid}{desc} );
			my $channel = encode_entities( $prog{$pid}{channel} );
			print HTML "<tr>
					<td rowspan=2 width=150><a href=\"${prog_page_prefix}/${pid}.html\"><img height=84 width=150 src=\"$prog{$pid}{thumbnail}\"></a></td>
					<td>$_</td>
					<td><a href=\"${prog_page_prefix}/${pid}.html\">${name}</a></td>
					<td>${episode}</td>
					<td>${channel}</td>
				</tr>
				<tr>
					<td colspan=5>${desc}</td>
				</tr>
			\n";
		}
		print HTML '</table></body>';
		close (HTML);
	} else {
		logger "Couldn't open html file $opt{html} for writing\n";
	}
}



# Save options to file
sub save_options_file {
	my $optfile = shift;
	unlink $optfile;
	logger "DEBUG: Saving options to $optfile:\n" if $opt{debug};
	open (OPT, "> $optfile") || die ("ERROR: Cannot save options to $optfile\n");
	# Save all opts except for these
	for (grep !/(help|test|debug|get)/, keys %opt) {
		print OPT "$_ $opt{$_}\n"  if defined $opt{$_};
		logger "DEBUG: Setting option $_ = $opt{$_}\n" if $opt{debug} && defined $opt{$_};
	}
	close OPT;
	logger "INFO: Options saved as defult in $optfile\n";
	exit 0;
}



# Load default options from file
sub read_options_file {
	my $optfile = shift;
	return 0 if ! -f $optfile;
	logger "DEBUG: Parsing options from $optfile:\n" if $opt{debug};
	open (OPT, "< $optfile") || die ("ERROR: Cannot read options file $optfile\n");
	while(<OPT>) {
		/^\s*([\w\-_]+)\s+(.*)\s*$/;
		chomp( $opt{$1} = $2 );
		logger "DEBUG: Setting option $1 = $2\n" if $opt{debug};
	}
	close OPT;
}



# Get time ago made available (x days y hours ago) from '2008-06-22T05:01:49Z' and current time
sub get_available_time_string {
	my $datestring = shift;
	# extract $year $mon $mday $hour $min $sec
	$datestring =~ m{(\d\d\d\d)\-(\d\d)\-(\d\d)T(\d\d):(\d\d):(\d\d)Z};
	my ($year, $mon, $mday, $hour, $min, $sec) = ($1, $2, $3, $4, $5, $6);
	# Calculate the seconds difference between epoch_now and epoch_datestring and convert back into array_time
	my @time = gmtime( time() - timelocal($sec, $min, $hour, $mday, ($mon-1), ($year-1900), undef, undef, 0) );
	return "$time[7] days $time[2] hours ago";
}



# get full episode metadata given pid and ua. Uses two different urls to get data
sub get_pid_metadata {
	my $ua = shift;
	my $pid = shift;
	my $metadata;
	my $entry;
	my $entry2;

	# This URL works for all prog types:
	# http://www.bbc.co.uk/iplayer/playlist/${pid}

	# This URL only works for TV progs:
	# http://www.bbc.co.uk/iplayer/metafiles/episode/${pid}.xml

	# This URL works for tv/radio prog types:
	# http://www.bbc.co.uk/iplayer/widget/episodedetail/episode/${pid}/template/mobile/service_type/tv/

	# Only supply this if a TV prog
	if ( $prog{$pid}{type} =~ /tv/i ) {
		logger "DEBUG: Getting episode data for ${pid}\n" if $opt{verbose};
		$entry = request_url_retry($ua, "${metadata_xml_prefix}/${pid}.xml", 3, '', '');
		decode_entities($entry);
		# Flatten
		$entry =~ s|\n| |g;
		# Remove any related programme data
		$entry =~ s|<relatedConcepts>.*$||gi;
	}

	if ( $prog{$pid}{type} =~ /(tv|radio)/i ) {
		$entry2 = request_url_retry($ua, "${metadata_mobile_prefix}/${pid}/template/mobile/service_type/tv/", 3, '', '');
		decode_entities($entry2);
		# Flatten
		$entry2 =~ s|\n| |g;
		# Remove any related programme data
		$entry2 =~ s|<relatedConcepts>.*$||gi;
	}


	# entry Format:
	# <?xml version="1.0" encoding="UTF-8"?> <iplayerMedia version="0.2">    <concept>          <pid>b00c7ytx</pid>
	#     <url>http://www.bbc.co.uk/iplayer/page/item/b00c7ytx.shtml</url>     <title>Doctor Who: Series 4</title>
	#     <subtitle>Turn Left</subtitle>     <thumbnail>    
	#   <url>http://www.bbc.co.uk/iplayer/images/episode/b00c7ytx_512_288.jpg</url>   
	#    <width>512</width>       <height>288</height>       <mediaType>image/jpeg</mediaType>     </thumbnail>  
	#    <shortSynopsis>Can Donna and Rose stop the approaching Darkness?</shortSynopsis>  
	#   <mediumSynopsis>As Donna's world collapses, she finds help from a mysterious blonde woman - but can Donna and Rose stop the approaching Darkness?</mediumSynopsis>  
	#   <longSynopsis></longSynopsis>     <masterbrand id="bbc_one">  
	#     <thumbnail>         <url>http://www.bbc.co.uk/iplayer/framework/img/ch/bbc_one.gif</url>         <width>54</width> 
	#<!-- Note:these value are currently hard coded as they're not in the content package -->         <height>40</height>     
	#     <mediaType>image/gif</mediaType>       </thumbnail>   
	#    <ident>          <server>cp44293.edgefcs.net</server>          <identifier>public/bbc_one</identifier>    
	#     <width>512</width>         <height>288</height>         <mediaType>video/x-flv</mediaType>       </ident>     </masterbrand>      
	#   <versions><!-- there will only be one version for launch. This will be the first available version -->  
	#      <version>           <name>AudioDescribed,Original</name>      
	#     <pid>b00c7yq9</pid>           <guidance>             <text></text>           </guidance>     
	#      <duration>00:45:00</duration>            <available>true</available>         </version>              </versions>
	
	# entry2 Format:
	# 	<h1>Doctor Who: Series 4</h1>
	#<div id="p-panel-episode">
	#        <div id="episode-image">
	#                <a href="#" id="version" pid="b00c7yq9"><img id="play-version" pid="b00c7yq9" src="img/click_to_play.png" /></a>
	#                <img src="/iplayer/images/episode/b00c7ytx_314_176.jpg" />
	#                <div id="player-container"></div>
	#
	#                <div id="info-message"></div>
	#        </div>
	#        <h2>Turn Left <span>-  45 mins</span></h2>
	#        <p><img class="episode-masterbrand" src="img/bbc_one.png"> As Donna's world collapses, she finds help from a mysterious blonde woman - but can Donna and Rose stop the approaching Darkness?</p>
	#        <p>Available till:  8:54pm Friday 11th July</p>

	# Format: http://www.bbc.co.uk/iplayer/playlist/b00c8ssg
	#<?xml version="1.0" encoding="UTF-8"?>
	#
	#<playlist xmlns="http://bbc.co.uk/2008/emp/playlist" revision="1">
	#  <id>tag:bbc.co.uk,2008:iplayer:b00c8ssg:playlist</id>
	#  <link rel="self" href="http://www.bbc.co.uk/iplayer/playlist/b00c8ssg"/>
	#  <link rel="alternate" href="http://www.bbc.co.uk/iplayer/episode/b00c8ssg"/>
	#  <link rel="holding" href="http://www.bbc.co.uk/iplayer/images/episode/b00c8ssg_640_360.jpg" height="360" width="640" type="image/jpeg" />
	#  <title>Eddie Halliwell: 03/07/2008</title>
	#  <summary>With two hours of the best new trance and techno.</summary>
	#  <updated>2008-06-26T01:01:37Z</updated>
	#  <item kind="radioProgramme" duration="7200" identifier="b00c8smr" group="b00c8ssg" publisher="pips">
	#    <title>Eddie Halliwell: 03/07/2008</title>
	#    <broadcast>2008-07-03T23:00:00</broadcast>
	#    <service id="bbc_radio_one" href="http://www.bbc.co.uk/iplayer/bbc_radio_one">BBC Radio 1</service>
	#    <masterbrand id="bbc_radio_one" href="http://www.bbc.co.uk/iplayer/bbc_radio_one">BBC Radio 1</masterbrand>
	#    <passionSite href="http://www.bbc.co.uk/programmes/b006wq9w/microsite">Eddie Halliwell</passionSite>
	#    <mediator identifier="b00c8smr" name="pips"/>
	#  </item>
	#</playlist>

	my ($duration, $available, $channel, $expiry, $longdesc, $versions, $guidance);

	$expiry = $1 if $entry2 =~ m{<p>Available till:\s*(.*?)\s*</p>};
	$duration = $1 if $entry =~ m{<duration>\s*(.*?)\s*</duration>};
	$channel = $1 if $entry =~ m{<masterbrand id="\s*(.*?)\s*">};
	$available = $1 if $entry =~ m{<available>\s*(.*?)\s*</available>};
	$longdesc = $1 if $entry =~ m{<longSynopsis>\s*(.*?)\s*</longSynopsis>};
	if (! $longdesc) {
		$longdesc = $1 if $entry =~ m{<mediumSynopsis>\s*(.*?)\s*</mediumSynopsis>};
	}
	if (! $longdesc) {
		$longdesc = $1 if $entry =~ m{<shortSynopsis>\s*(.*?)\s*</shortSynopsis>};
	}
	$versions = $1 if $entry =~ m{<name>\s*(.*?)\s*</name>};
	$guidance = $1 if $entry =~ m{<guidance>\s*<text>\s*(.*?)\s*</text>};

	# Fill in from cache if not got from metadata
	$metadata .= "\nPid:\t\t$pid\n";
	$metadata .= "Index:\t\t$prog{$pid}{index}\n";
	$metadata .= "Duration:\t".	($duration || $prog{$pid}{duration})	."\n";
	$metadata .= "Channel:\t".	($channel || $prog{$pid}{channel})	."\n";
	$metadata .= "Available:\t".	($available || $prog{$pid}{available})	."\n";
	$metadata .= "Expires:\t".	($expiry || $prog{$pid}{expiry})	."\n";
	$metadata .= "Versions:\t".	($versions || $prog{$pid}{versions})	."\n";
	$metadata .= "Guidance:\t".	($guidance || $prog{$pid}{guidance})	."\n";
	$metadata .= "Categories:\t".	$prog{$pid}{categories}			."\n";
	$metadata .= "Description:\t".	($longdesc || $prog{$pid}{desc})	."\n";

	return $metadata;
}



# Gets the contents of a URL and retries if it fails, returns '' if no page could be retrieved
# Usage <content> = request_url_retry(<ua>, <url>, <retries>, <succeed message>, [<fail message>]);
sub request_url_retry {
	my ($ua, $url, $retries, $succeedmsg, $failmsg) = @_; 
	my $res;

	my $i;
	logger "INFO: Getting page $url\n" if $opt{verbose};
	for ($i = 0; $i < $retries; $i++) {
		$res = $ua->request( HTTP::Request->new( GET => $url ) );
		if ( ! $res->is_success ) {
			logger $failmsg;
		} else {
			logger $succeedmsg;
			last;
		}
	}
	# Return empty string if we failed
	return '' if $i == $retries;
	# otherwise return content
	return $res->content;
}



# Checks if a particular program exists (or program.exe) in the $ENV{PATH} or if it has a path already check for existence of file
sub exists_in_path {
	my $file = shift;
	# If this has a path specified, does file exist
	return 1 if $file =~ /[\/\\]/ && (-f $file || -f "${file}.exe");
	# Search PATH
	for (@PATH) {
		return 1 if -f "${_}/${file}" || -f "${_}/${file}.exe";
	}
	return 0;
}



# Run a user specified command
# e.g. --command 'echo "<pid> <longname> downloaded"'
# run_user_command($pid, 'echo "<pid> <longname> downloaded"');
sub run_user_command {
	my $pid = shift;
	my $command = shift;

	# Tokenize and substitute $format
	for my $key ( keys %{ $prog{$pid} } ) {
		$command =~ s|\<$key\>|$prog{$pid}{$key}|gi;
	}
	$command =~ s|<pid>|$pid|gi;

	# Escape chars in command for shell use
	esc_chars(\$command);

	# run command
	logger "INFO: Running command '$command'\n" if $opt{verbose};
	my $exit_value = system $command;
	
	# make exit code sane
	$exit_value = $exit_value >> 8;
	logger "ERROR: Command Exit Code: $exit_value\n" if $exit_value;
	logger "INFO: Command succeeded\n" if $opt{verbose} && ! $exit_value;
        return 0;
}



# Adds pid to history file (with a timestamp) so that it is not redownloaded after deletion
sub add_to_download_history {
	my $pid = shift;
	# Only add if a pid is specified
	return 0 if ! $pid;
	# Don't add to history if stdout streaming is used
	return 0 if ( $opt{stdout} && $opt{nowrite} ) || $opt{streaminfo};

	# Add to history
	if ( ! open(HIST, ">> $historyfile") ) {
		logger "WARNING: Cannot write or append to $historyfile\n\n";
		return 1;
	}
	print HIST "$pid|$prog{$pid}{name}|$prog{$pid}{episode}|$prog{$pid}{type}|".time()."\n";
	close HIST;
	return 0;
}



# Checks history for previous download of this pid
sub check_download_history {
	my $pid = shift;

	# Return if force-download option specified or stdout streaming only
	return 0 if $opt{forcedownload} || $opt{stdout} || $opt{nowrite};
	
	if ( ! open(HIST, "< $historyfile") ) {
		logger "WARNING: Cannot read $historyfile\n\n";
		return 0;
	}

	if ( $pid && grep /^$pid/, <HIST>) {
		logger "INFO: $pid Already in download history ($historyfile)\n";
		close HIST;
		return 1;

	} else {
		logger "INFO: PID not in download history\n" if $opt{verbose};
		close HIST;
		return 0;
	}
}



# Add id3 tag to MP3 files if required
sub tag_file {
	my $pid = shift;
	if ( $prog{$pid}{ext} eq 'mp3' ) {
		# Create ID3 tagging options for external tagger program (escape " for shell)
		my ( $id3_name, $id3_episode, $id3_desc, $id3_channel ) = ( $prog{$pid}{name}, $prog{$pid}{episode}, $prog{$pid}{desc}, $prog{$pid}{channel} );
		$id3_name =~ s|"|\"|g for ($id3_name, $id3_episode, $id3_desc, $id3_channel);
		# Only tag if the required tool exists
		if ( exists_in_path($id3v2) ) {
			logger "INFO: id3 tagging MP3 file\n";
			my $cmd = "$id3v2 --artist \"$id3_channel\" --album \"$id3_name\" --song \"$id3_episode\" --comment \"Description\":\"$id3_desc\" --year ".( (localtime())[5] + 1900 )." $prog{$pid}{filename} 1>&2";
			logger "DEGUG: Running $cmd\n" if $opt{debug};
			if ( system($cmd) ) {
				logger "WARNING: Failed to tag MP3 file\n";
				return 2;
			}
		} else {
			logger "WARNING: Cannot tag MP3 file\n" if $opt{verbose};
		}
	}
}



# Show channels for specified type if required
sub list_unique_element_counts {
	my $element_name = shift;
	my %elements;
	logger "INFO: $opt{type} $element_name List:\n" if $opt{verbose};
	for my $pid (keys %prog) {
		for my $element ( split /,/, $prog{$pid}{$element_name} ) {
			$elements{ $element }++;
		}
	}
	# display element + prog count
	logger "$_ ($elements{$_})\n" for sort keys %elements;
	return 0;
}



# Escape chars in string for shell use
sub esc_chars {
	# will change, for example, a!!a to a\!\!a
	s/([;<>\*\|&\$!#\(\)\[\]\{\}:'"])/\\$1/g;
	return $_;
}



# Signal handler to clean up after a ctrl-c or kill
sub cleanup {
	logger "Cleaning up\n" if $opt{verbose};
	unlink $namedpipe;
	exit 1;
}
